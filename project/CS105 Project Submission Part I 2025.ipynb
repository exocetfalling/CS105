{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Singapore Management University<br>\n",
    "CS105 Statistical Thinking for Data Science, 2024/25 Term 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYBbWb-0Kc6H"
   },
   "source": [
    "# CS105 Group Project Submission (Part I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Provide your team details, including section, team number, team members, and the name of the dataset. \n",
    "Complete all of the following sections. For any part requiring code to derive your answers, please create a code cell immediately below your response and run the code.\n",
    "To edit any markdown cell, double click the cell; after editing, execute the markdown cell to collapse it.\n",
    "<br>\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration\n",
    "\n",
    "<span style=\"color:red\">By submitting this notebook, we declare that **no part of this submission is generated by any AI tool**. We understand that AI-generated submissions will be considered as plagiarism, and just like other plagirisum cases, disciplinary actions will be imposed.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section:   G5\n",
    "#### Team:      T1\n",
    "#### Members:\n",
    "1. Zachary Tay\n",
    "2. Bryan Lee\n",
    "3. Ang Qi Long\n",
    "4. Jonathan Wong\n",
    "5. Swayam Jain\n",
    "\n",
    "#### Dataset: Employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('employee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"menu\"></a>\n",
    "#### Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. [Overview of Dataset](#part1)\n",
    "2. [Data Pre-processing](#part2)\n",
    "3. [Exploratory Analysis and Visualization](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Exploratory Data Analysis (EDA) [8% of final grade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "### 1. Overview of dataset [15% of Part I]\n",
    "a. [Background](#part1a) <br>\n",
    "b. [Size](#part1b) <br>\n",
    "c. [Variables](#part1c)\n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** Summarise the background of the dataset [limited to 50 words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "This dataset contains <b>HR data of all employees under a sales team</b>. The data includes <b>personal and employment details</b>, <b>total career sales acquired</b> and <b>latest quarterly rating</b>. An employee’s data is <b>captured at the beginning of each month</b>, either <b>up to the latest month</b> (Dec 2017) or <b>when they quit</b>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b.** State the size of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size**\n",
    "- **Rows**: 2381\n",
    "- **Columns**: 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1c\"></a> [(Back)](#part1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** For each variable, describe what it represents and its data type (numerical or categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**\n",
    "- **Type**: Categorical (?Nominal?)<br>\n",
    "- **Info**: The date when the specific row’s data is recorded \n",
    "\n",
    "**Emp_ID**\n",
    "- **Type**: Categorical (Nominal)<br>\n",
    "- **Info**: The unique ID of the employee\n",
    "\n",
    "**Age**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: The age of the employee\n",
    "  \n",
    "**Gender**\n",
    "- **Type**: Categorical (Nominal)<br>\n",
    "- **Info**: The employee’s gender (Male or Female)\n",
    "\n",
    "**City**\n",
    "- **Type**: Categorical (?)<br>\n",
    "- **Info**: The city where the employees works in (C1, C2, ..., C29)\n",
    "\n",
    "**Education**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Highest education of the employee (College, Bachelor, Master)\n",
    "\n",
    "**Salary**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: Current salary of the employee excluding bonus \n",
    "\n",
    "**Join_Date**\n",
    "- **Type**: Categorical (?Nominal?)<br>\n",
    "- **Info**: The date when the employee joins the company\n",
    "\n",
    "**Last_Work_Date**\n",
    "- **Type**: Categorical (?Nominal?)<br>\n",
    "- **Info**: The data when the employee leaves the company, otherwise empty if employee has not quit\n",
    "\n",
    "**Join_Designation**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Designation level when the employee joined the company (1, 2, 3, 4, 5)\n",
    "\n",
    "**Designation**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Current designation level of the employee (1, 2, 3, 4, 5)\n",
    "\n",
    "**Total_Sales**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: Total sales generated by the employee since joining the team\n",
    "\n",
    "**Quarterly_Rating**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Last quarterly performance rating (1, 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Back)](#part1) <a id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## 2. Data pre-processing [35% of Part I]\n",
    "a. [Missing Data](#part2a) <br>\n",
    "b. [Outlier](#part2b) <br>\n",
    "c. [Encoding](#part2c)                                   \n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** For each variable, determine the percentage of missing data. For any column with missing data, describe how you resolve the issue. Clearly state any assumption you made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable w/ Missing Data | Count | Percentage |\n",
    "| :---------------- | :------: | ----: |\n",
    "| Join_Date | 118 | 4.96% |\n",
    "| Last_Work_Date | 765 | 32.13% |\n",
    "| Join_Designation | 105 | 4.41% |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayMissing() :\n",
    "    missing_count = df.shape[0] - df.count()              # total rows - rows with non-null values\n",
    "    missing_percent = (missing_count / df.shape[0] * 100) # missing rows / total rows\n",
    "\n",
    "    missing_data = pd.DataFrame({'Count': missing_count, 'Percentage': round(missing_percent,2)})\n",
    "    missing_data = missing_data[missing_data['Count'] > 0]  # filter out variable w/o missing data\n",
    "\n",
    "    return missing_data\n",
    "\n",
    "displayMissing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**\n",
    "- **Resolution**: Drop all rows with missing `Join_Date`\n",
    "- **Reason**: As data of an employee is updated every month, there is no past record to check for their join date. We therefore cannot reasonably accertain when they joined the sales team. Additionally, as the duration of employement will impact other variables and the percentage of missing data is not too high (4.96%), we opted to drop these rows with missing `Join_Date`\n",
    "- **Assumption(s)**:\n",
    "    - Each employee will only have one Emp_ID unique to them\n",
    "    - An employee who had quit will not join the sales team again nor gain a new Emp_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Join_Date'], inplace = True)         # drop all rows with null values under Join_Date\n",
    "displayMissing()                                        # Join_Date count is 0 (LWD & JD are affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**\n",
    "- **Resolution**: For rows with missing `Last_Work_Date`,\n",
    "    - If `Date` is before 1/12/2017, drop rows\n",
    "    - If `Date` is 1/12/2017, impute rows with 31/12/2017\n",
    "- **Reason**: \n",
    "    - For rows before Dec 2017, an older `Date` suggests that the employee is no longer with the sales team. The employee may quit on anyday within a given month and make any number of sales in that period too, thus affecting the other variables. As we again cannot reasonably accertain when the employee quit and number of affected is not too high (24, 1.06%), we opted to drop these rows with missing 'Last_Work_Date`\n",
    "    - For rows during Dec 2027, `Last_Work_Date` being blank indicates that the employee has not quit in that given month. As such, we can state that the date they last worked (or are employed) is 31 Dec 2017 and opted to impute with this date.\n",
    "- **Assumption(s)**: \n",
    "    - There are no other employees who quit within Dec 2017 beyond those given in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "unknownLastDate = df[(df['Last_Work_Date'].isnull()) & (df['Date'] < '2017-12-01')].shape[0]\n",
    "print(\"Unknown Last Date:\", unknownLastDate, round(unknownLastDate / df.shape[0] * 100, 2), \"%\")\n",
    "\n",
    "stillWorking = df[(df['Last_Work_Date'].isnull()) & (df['Date'] == '2017-12-01')].shape[0]\n",
    "print(\"Still Working:\", stillWorking, round(stillWorking / df.shape[0] * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknownLastDate = df[(df['Last_Work_Date'].isnull()) & (df['Date'] < '2017-12-01')]     # splice out rows where Date is before Dec 2017\n",
    "df.drop(unknownLastDate.index, inplace=True)                                            # use index of unknownLastDate and drop row\n",
    "\n",
    "df.fillna({\"Last_Work_Date\": \"31/12/2017\"}, inplace=True)                               # impute rows of employees still working with sales team\n",
    "                                                                                        # with last day of month (31 Dec 2017)\n",
    "\n",
    "displayMissing()                                                                        # Last_Work_Date is 0 (JD affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation**\n",
    "- **Resolution**: For rows with missing `Join_Designation`, \n",
    "    - If `Designation == 1`, impute rows with 1\n",
    "    - If `Designation > 1`, drop these rows\n",
    "- **Reason**: \n",
    "    - As `Designation` captures the current designation level of an employee when their data was recorded, if current designation level is 1, then we can definitvely deduce that the `Join_Designation` is 1 too. \n",
    "    - For any higher current designation level than 1, we again cannot reasonably accertain their initial designation level as it likely varies with other variables. As the number and percentage of rows missing data where `Designation > 1`  is not too high (78, 3.48%), we opted to drop these rows and impute those where where `Designation == 1` is 1 (22, 0.983%) with 1  \n",
    "- **Assumption(s)**: -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdIs1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] == 1)].shape[0]\n",
    "cdNot1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] != 1)].shape[0]\n",
    "\n",
    "print(\"(Current) Designation = 1:\", cdIs1, round(cdIs1 / df.shape[0] * 100, 3), \"%\")\n",
    "print(\"(Current) Designation > 1:\", cdNot1, round(cdNot1 / df.shape[0] * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdNot1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] != 1)]   # splice out rows where designation > 1\n",
    "df.drop(cdNot1.index, inplace=True)                                         # use index of cdNot1 and drop row\n",
    "# print(cdNot1.shape[0])\n",
    "\n",
    "cdIs1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] == 1)]    # splice out rows where designation is 1\n",
    "# print(cdIs1.iloc[cdIs1[cdIs1[\"Emp_ID\"]==21].index])\n",
    "df.loc[cdIs1.index, \"Join_Designation\"] = 1                                 # use index of cdIs1 and impute row with 1\n",
    "# print(cdIs1.shape[0])\n",
    "# print(df.iloc[df[df[\"Emp_ID\"]==21].index])\n",
    "\n",
    "df['Join_Designation'] = df['Join_Designation'].astype(int)                 # convert imputed float (1.0) to int (1)\n",
    "# print(df.iloc[df[df[\"Emp_ID\"]==21].index])\n",
    "displayMissing()                                                            # Join_Designation count is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size after Cleaning**\n",
    "- **Rows**: 2161\n",
    "- **Columns**: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2b\"></a> [(Back)](#part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **b.** For each variable, identify outliers (if any) and describe how you resolve the issue. Clearly state any assumption you made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age**\n",
    "There exists 33 outlier rows with `Age` above upper bound.\n",
    "- **Resolution**: Remove the row with the outlier with the employee of the oldest age.\n",
    "- **Reason**: This outlier is siginficantly further away from the rest of the cluster\n",
    "- **Assumption(s)**: \n",
    "    - An employee is not forced to quit or retire once they reach a certain age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "Q1 = df[\"Age\"].quantile(0.25)\n",
    "Q3 = df[\"Age\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is 17 years old                \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is 49 years old\n",
    "\n",
    "below = df[df['Age'] <= lower].shape[0]\n",
    "above = df[df['Age'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows below lower bound ({int(lower)}): {below}\")\n",
    "print(f\"Rows below upper bound ({int(upper)}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Age\"]].boxplot()\n",
    "plt.title(\"Age\")\n",
    "plt.ylabel(\"Years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the oldest person\n",
    "max_age = df.Age.max()\n",
    "age_outlier = df[df[\"Age\"] == max_age]\n",
    "age_outlier\n",
    "df.drop(age_outlier.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Age\"].quantile(0.25)\n",
    "Q3 = df[\"Age\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is 17 years old                \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is 49 years old\n",
    "\n",
    "below = df[df['Age'] <= lower].shape[0]\n",
    "above = df[df['Age'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows below lower bound ({int(lower)}): {below}\")\n",
    "print(f\"Rows below upper bound ({int(upper)}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Age\"]].boxplot()\n",
    "plt.title(\"Age\")\n",
    "plt.ylabel(\"Years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary**\n",
    "There exists 50 outlier rows with `Salary` above upper bound.\n",
    "- **Resolution**:\n",
    "    - Drop the 3 outliers separated from the cluster\n",
    "    - Keep the outliers within the cluster\n",
    "- **Reason**:\n",
    "    - As there is only 3 such outliers that are much further away from the rest of the points, we opted to drop them.\n",
    "    - Likely corresponds to employee with higher designation level. As such, we should keep these outliers for our data analysis\n",
    "- **Assumption(s)**: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers for salary\n",
    "\n",
    "Q1 = df[\"Salary\"].quantile(0.25)\n",
    "Q3 = df[\"Salary\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is $129844.75\n",
    "\n",
    "below = df[df['Salary'] <= lower].shape[0]\n",
    "above = df[df['Salary'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows below lower bound (${lower}): {below}\")\n",
    "print(f\"Rows below upper bound (${upper}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Salary\"]].boxplot()\n",
    "plt.ylabel(\"Dollars ($)\")\n",
    "plt.show()\n",
    "\n",
    "df.sort_values('Salary', ascending=False)[[\"Emp_ID\", \"Salary\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 3 outliers\n",
    "top_3_outliers = df.sort_values(\"Salary\", ascending=False).head(3)\n",
    "df.drop(top_3_outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Acquired**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists 10 rows with negative `Total_Sales_Acquired`.\n",
    "- **Resolution**: Drop such rows with negative `Total_Sales_Acquired`\n",
    "- **Reason**: Total sales acquired should minimally be 0, not negative. We should not absolute these negative values or impute with 0 as we cannot reasonably accertain true total sales.\n",
    "- **Assumption(s)**:\n",
    "    - Dataset does not keep track whether an employee caused a loss of sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists 307 outlier rows with `Total_Sales_Acquired` above upper bound.\n",
    "- **Resolution**: Drop the top 3 rows that have outliers.\n",
    "- **Reason**: These outliers are siginficantly further away from the rest of the data points, hence, we have decided to drop them. \n",
    "- **Assumption(s)**: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Total_Sales_Acquired\"].quantile(0.25)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is                 \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is \n",
    "\n",
    "negative = df[df['Total_Sales_Acquired'] < 0].shape[0]\n",
    "below = df[df['Total_Sales_Acquired'] <= lower].shape[0]\n",
    "above = df[df['Total_Sales_Acquired'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows with negative sales: {negative}\");\n",
    "print(f\"Rows below lower bound ({lower}): {below}\")\n",
    "print(f\"Rows below upper bound ({upper}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Total_Sales_Acquired\"]].boxplot()\n",
    "plt.ylabel(\"Sales (x10^8)\")\n",
    "plt.show()\n",
    "\n",
    "df.sort_values('Total_Sales_Acquired', ascending=False)[[\"Emp_ID\", \"Total_Sales_Acquired\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with negative sales\n",
    "negativeSales = df[df['Total_Sales_Acquired'] < 0]  \n",
    "df.drop(negativeSales.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 3 outliers\n",
    "top_3_outliers = df.sort_values(\"Total_Sales_Acquired\", ascending=False).head(3)\n",
    "df.drop(top_3_outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size after Handling Outliers**\n",
    "- **Rows**: 2144\n",
    "- **Columns**: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2c\"></a> [(Back)](#part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** For categorical variables, perform the necessary encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp ID, Join Designation, Designation, Quarterly Rating**\n",
    "\n",
    "These categorical variables are stored as `int` and therefore need not be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender**\n",
    "Binary (nominal) variable; To apply binary encoding \n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|Male|0|\n",
    "|Female|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoding = {\"Male\":0, \"Female\":1} \n",
    "df[\"Gender_Encoded\"] = df[\"Gender\"].map(gender_encoding)  # map Gender column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Gender\", \"Gender_Encoded\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City**\n",
    "Ordinal variable; To apply ordinal encoding\n",
    "Extract city number\n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|C1|1|\n",
    "|C2|2|\n",
    "|...|...|\n",
    "|C28|28|\n",
    "|C29|29|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoding = {\"C1\":1, \"C2\":2, \"C3\":3, \"C4\":4 ,\"C5\":5 ,\"C6\":6,\"C7\":7,\"C8\":8,\"C9\":9,\"C10\":10,\"C11\":11, \"C12\":12, \"C13\":13, \"C14\":14, \"C15\":15 ,\"C16\":16 ,\"C17\":17,\"C18\":18,\"C19\":19,\"C20\":20,\"C21\":21,\"C22\":22, \"C23\":23, \"C24\":24, \"C25\":25, \"C26\":26 ,\"C27\":27 ,\"C28\":28,\"C29\":29}\n",
    "\n",
    "df[\"City_Encoded\"] = df[\"City\"].map(city_encoding) #map City column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"City\", \"City_Encoded\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education**\n",
    "Ordinal variable; To apply ordinal encoding\n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|College|0|\n",
    "|Bachelor|1|\n",
    "|Master|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_encoding = {\"College\":0, \"Bachelor\":1, \"Master\":2} \n",
    "df[\"Education_Encoded\"] = df[\"Education\"].map(education_encoding)  # map Gender column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Education\", \"Education_Encoded\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice month and year from `Date`<br>\n",
    "Day is not needed as data is always captured at beginning of each month (i.e. 1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)  # already converted above\n",
    "\n",
    "df[\"Recorded_Month\"] = df['Date'].dt.month\n",
    "df[\"Recorded_Year\"] = df['Date'].dt.year\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Recorded_Month\", \"Recorded_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice day, month and year from `Join_Date`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], dayfirst=True)  \n",
    "\n",
    "df[\"Join_Day\"] = df['Join_Date'].dt.day\n",
    "df[\"Join_Month\"] = df['Join_Date'].dt.month\n",
    "df[\"Join_Year\"] = df['Join_Date'].dt.year\n",
    "\n",
    "df[[\"Emp_ID\", \"Join_Date\", \"Join_Day\", \"Join_Month\", \"Join_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice day, month and year from `Last_Work_Date`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Work_Date'] = pd.to_datetime(df['Last_Work_Date'], dayfirst=True)  \n",
    "\n",
    "df[\"LWD_Day\"] = df['Last_Work_Date'].dt.day\n",
    "df[\"LWD_Month\"] = df['Last_Work_Date'].dt.month\n",
    "df[\"LWD_Year\"] = df['Last_Work_Date'].dt.year\n",
    "\n",
    "df[[\"Emp_ID\", \"Last_Work_Date\", \"LWD_Day\", \"LWD_Month\", \"LWD_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Back)](#part2)\n",
    "<a id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3.\tExploratory analysis and visualization [50% of Part I]\n",
    "a. [Summary Statistics](#part3a) <br>\n",
    "b. [Visualisaton](#part3b) <br>\n",
    "c. [Bi-Variate Analysis](#part3c)\n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** For each variable, provide relevant summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCategorical(column):\n",
    "    value_counts = df[column].value_counts()\n",
    "    percentage = (value_counts / df.shape[0]) * 100\n",
    "\n",
    "    col_data = pd.DataFrame({'Count': value_counts.values, 'Percentage': round(percentage, 2)})    \n",
    "    return col_data.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp_ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Emp_ID.nunique()\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"# unique employee IDs : {unique_count}\")\n",
    "print(f\"# rows : {n_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Age\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(\"Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df[\"City\"].value_counts()                # Cannot sort normally by City(str) as \"C10\" < \"C2\" \n",
    "percentage = (value_counts / df.shape[0]) * 100\n",
    "col_data = pd.DataFrame({'Code':df[\"City_Encoded\"].value_counts().index,'Count': value_counts.values, 'Percentage': round(percentage, 2)})    \n",
    "col_data.sort_values(by=\"Code\").drop(columns=[\"Code\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Education.nunique()\n",
    "print(f\"# unique types of education : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Salary\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Join_Date.nunique()\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"# unique join dates : {unique_count}\")\n",
    "print(f\"# rows : {n_rows}\")\n",
    "print()\n",
    "\n",
    "classes = df.Join_Date.unique()\n",
    "print(f\"Values of join dates : {classes}\")\n",
    "\n",
    "all_join_dates = df.Join_Date.mode()[0]  # note that .mode() returns a series so we need to access the first element using [0]\n",
    "df.Join_Date.value_counts()  # do a count to verify the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Last_Work_Date.nunique()\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"# unique last work dates : {unique_count}\")\n",
    "print(f\"# rows : {n_rows}\")\n",
    "print()\n",
    "\n",
    "classes = df.Last_Work_Date.unique()\n",
    "print(f\"Values of last work dates : {classes}\")\n",
    "\n",
    "all_join_dates = df.Last_Work_Date.mode()[0]  # note that .mode() returns a series so we need to access the first element using [0]\n",
    "df.Last_Work_Date.value_counts()  # do a count to verify the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Join_Designation.nunique()\n",
    "print(f\"# unique types of join designations : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Join_Designation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Designation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Designation.nunique()\n",
    "print(f\"# unique types of designations : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Designation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Acquired**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Total_Sales_Acquired\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quarterly Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Quarterly_Rating.nunique()\n",
    "print(f\"# unique types of ratings : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Quarterly_Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3b\"></a> [(Back)](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b.** For each variable, provide an appropriate visualisation depicting the distribution of its values, and summarize any key observation(s) you made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date** <a id=\"p3b1\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - Dec 2017 has the most data recorded as it includes those of employees that are still working (663) and have quit (72)\n",
    "    - Other Date being non-zero represents those employees who had quit within that month\n",
    "        - The distribution of employees who quit in a given month appears relatively uniform\n",
    "        - In 2016, May had the most employees who quit\n",
    "        - In 2017, July had the most employees who quit\n",
    "        - In both years, April had the least employees who quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stillWorking = df[(df['Last_Work_Date']==\"31/12/2017\")].shape[0]\n",
    "dec2017 = df[(df['Date']==\"2017-12-01\")].shape[0]\n",
    "print(f\"Still Working in Dec 2017: {stillWorking}\")\n",
    "print(f\"Quit in Dec 2017: {dec2017-stillWorking}\")\n",
    "\n",
    "date_data = df[\"Date\"].value_counts(normalize=False)\n",
    "date_level = date_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(date_level, date_data, width=15)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Date\", fontsize=15)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.xticks(date_level, date_level.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp ID** <a id=\"p3b2\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - Increment between Emp_ID is not always 1, possibly suggesting a loss of data for these employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count_emp = df.Emp_ID.nunique()\n",
    "n_rows = df.shape[0]\n",
    "\n",
    "print(f\"# Total unique Emp_ID : {unique_count_emp}\")\n",
    "print(f\"# Total Rows : {n_rows}\")\n",
    "\n",
    "df[df[\"Emp_ID\"] < 500].Emp_ID.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age** <a id=\"p3b3\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution of Age is slightly right-skewed (more data above median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Age\"]].boxplot()\n",
    "plt.title(\"Age\", fontsize=15)\n",
    "plt.ylabel(\"Years\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Age\", fontsize=15)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Age\"].hist(bins=20)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender** <a id=\"p3b4\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - There have been more males employees (59%) than female employees (41%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = df[\"Gender\"].value_counts(normalize=False)\n",
    "gender_level = gender_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(gender_level, gender_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Gender\", fontsize=15)\n",
    "plt.xlabel(\"Gender\", fontsize=12)\n",
    "# plt.xticks(gender_level, ['Male', 'Female'])\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City** <a id=\"p3b5\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - City C20 has had the greatest number of employees, suggesting it is a significant location\n",
    "    - The distribution across the other 28 cities appears relatively uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = df[\"City_Encoded\"].value_counts(normalize=False)\n",
    "city_level = city_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(city_level, city_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Cities\", fontsize=15)\n",
    "plt.xlabel(\"City No. \", fontsize=12)\n",
    "plt.xticks(range(1, 30))\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education** <a id=\"p3b6\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution across the 3 education levels is balanced, with College having a slightly lower count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_data = df[\"Education\"].value_counts(normalize=False)\n",
    "education_level = education_data.index\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "bars = plt.bar(education_level, education_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Education\", fontsize=15)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary** <a id=\"p3b7\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution of Salary is right-skewed (more data above median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Salary\"]].boxplot()\n",
    "plt.title(\"Salary\", fontsize=15)\n",
    "plt.ylabel(\"$\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Salary\", fontsize=15)\n",
    "plt.xlabel(\"Salary ($)\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Salary\"].hist(bins=50)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date** <a id=\"p3b8\"></a>\n",
    "- **Key Observation(s)**: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_count = df.Join_Date.nunique()\n",
    "print(f\"# unique join dates  : {jd_count}\")\n",
    "\n",
    "cols = [\"Join_Day\", \"Join_Month\", \"Join_Year\"]\n",
    "xaxes = [np.arange(1,32,1), np.arange(1,13,1), np.arange(2010,2018,1)]\n",
    "labels = [\"Day\", \"Month\", \"Year\"]\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    date_data = df[cols[i]].value_counts(normalize=False)\n",
    "    date_level = date_data.index\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(date_level, date_data)\n",
    "\n",
    "    for bar in bars:                               \n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.title(\"Join Date (\"+labels[i]+\")\", fontsize=15)\n",
    "    plt.xlabel(labels[i], fontsize=12)\n",
    "    plt.xticks(xaxes[i]) \n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date** <a id=\"p3b9\"></a>\n",
    "- **Key Observation(s)**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data = df.groupby(df[\"Last_Work_Date\"].dt.to_period('M'))[\"Last_Work_Date\"].count()\n",
    "date_level = date_data.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "bars = plt.bar(date_level, date_data, width=15)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Date\", fontsize=15)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.xticks(date_level, date_level.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwd_count = df.Last_Work_Date.nunique()\n",
    "print(f\"# unique last work date : {lwd_count}\")\n",
    "\n",
    "cols = [\"LWD_Day\", \"LWD_Month\", \"LWD_Year\"]\n",
    "xaxes = [np.arange(1,32,1), np.arange(1,13,1), np.arange(2015,2018,1)]\n",
    "labels = [\"Day\", \"Month\", \"Year\"]\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    date_data = df[cols[i]].value_counts(normalize=False)\n",
    "    date_level = date_data.index\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(date_level, date_data)\n",
    "\n",
    "    for bar in bars:                               \n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.title(\"Last Work Date (\"+labels[i]+\")\", fontsize=15)\n",
    "    plt.xlabel(labels[i], fontsize=12)\n",
    "    plt.xticks(xaxes[i]) \n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation** <a id=\"p3b10\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - Employees rarely join with designation level 4 or 5 (1.95%)\n",
    "    - An employee mostly likely joins with designation level 1 (44.21%)\n",
    "    - For each subsequent designation level, the employee count at that designation level decreases, with a significant drop between level 3 and 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_data = df[\"Join_Designation\"].value_counts(normalize=True)\n",
    "jd_level = jd_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))                \n",
    "bars = plt.bar(jd_level, jd_data)              \n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.2%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Designation Level\", fontsize=12)   \n",
    "plt.ylabel(\"Percentage\", fontsize=12)          \n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "plt.title(\"Employees' Designation Upon Joining\", fontsize=15) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Designation** <a id=\"p3b11\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - There is a significant drop in the number of employees at level 1 (11.81%)\n",
    "    - All other designation levels (2-5) have increased while following a similar trend as Join_Designation \n",
    "    - Designation level 3 has the greatest jump (5.02%)\n",
    "    - Designation level 5 is still the smallest (0.98%), suggesting it is difficult to be promoted to level 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_data = df[\"Designation\"].value_counts(normalize=True)\n",
    "cd_level = cd_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))                  \n",
    "bars = plt.bar(cd_level, cd_data)              \n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.2%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Designation Level\", fontsize=12)   \n",
    "plt.ylabel(\"Percentage\", fontsize=12)          \n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "plt.title(\"Employees' Latest Designation\", fontsize=15)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5)) \n",
    "\n",
    "jd_data = df[\"Join_Designation\"].value_counts(normalize=True)\n",
    "bars1 = plt.bar(jd_data.index - 0.2, jd_data, 0.4, label = 'First Joined') \n",
    "\n",
    "for bar in bars1:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "cd_data = df[\"Designation\"].value_counts(normalize=True)\n",
    "bars2 = plt.bar(cd_data.index + 0.2, cd_data, 0.4, label = 'Latest') \n",
    "  \n",
    "for bar in bars2:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Designation Level\", fontsize=12) \n",
    "plt.ylabel(\"Percentage\", fontsize=12)  \n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "plt.legend() \n",
    "plt.title(\"Employee's Designation\", fontsize=15)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Accquired** <a id=\"p3b12\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - A significant number of employees (653) accuqired 0 total sales such that the lower quantile and lower bound are both 0\n",
    "    - Among the outlier data\n",
    "        - The majority are concentrated between upper bound (0.1x10^8) and 0.4x10^8 total sales\n",
    "        - There is another grouping between 0.5x10^8 and 0.6x10^8 total sales\n",
    "        - There is 3 distinct points after 0.6x10^8 total sales\n",
    "    - The distribution of Total Sales Accquired is right-skewed (more data above median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Total_Sales_Acquired\"]].boxplot()\n",
    "plt.title(\"Total Sales Acquired\", fontsize=15)\n",
    "plt.ylabel(\"Sales (x10^8)\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Total Sales Acquired\", fontsize=15)\n",
    "plt.xlabel(\"Sales\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Total_Sales_Acquired\"].hist(bins=50)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_totalSalesAcquired = np.log1p(df.Total_Sales_Acquired)\n",
    "log_totalSalesAcquired.hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quarterly Rating** <a id=\"p3b13\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - Follows a logarithmic decrease, with a significant drop between rating 1 and 2\n",
    "    - The majority of employees are given a quarterly rating of 1, emphasising it is difficult to attain a higher rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_data = df[\"Quarterly_Rating\"].value_counts(normalize=True)\n",
    "qr_level = qr_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(qr_level, qr_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "plt.title(\"Employees' Quarterly Rating\", fontsize=15)\n",
    "plt.xlabel(\"Quarterly Rating\", fontsize=10)\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.ylabel(\"Percentage\", fontsize=10)\n",
    "plt.yticks(np.arange(0,0.9,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3c\"></a> [(Back)](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** Perform bi-variate analysis on the variables. You do not need to present the analysis of every pair of variables; only focus on the pairs you believe are worth investigating and explain. For each pair, describe the relationship between the two variables. Use appropriate statistical methods and/or visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Salary\"].quantile(0.25)\n",
    "Q3 = df[\"Salary\"].quantile(0.75)\n",
    "#lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def salary_class(n):   \n",
    "    if n > upper:\n",
    "        return \"Very high salary\"\n",
    "    elif n > Q3:\n",
    "        return \"High salary\"\n",
    "    elif n < Q1:\n",
    "        return \"Low salary\"\n",
    "    else:\n",
    "        return \"Middle salary\"\n",
    "    \n",
    "df[\"salaryClass\"] = df.Salary.apply(salary_class)\n",
    "\n",
    "df[[\"Emp_ID\", \"Salary\", \"salaryClass\"]].sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Total_Sales_Acquired\"].quantile(0.25)\n",
    "Q2 = df[\"Total_Sales_Acquired\"].quantile(0.50)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)\n",
    "#lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def salary_class(n):   \n",
    "    if n > upper:\n",
    "        return \"Very high sales\"\n",
    "    elif n > Q3:\n",
    "        return \"High sales\"\n",
    "    elif n < Q2:\n",
    "        return \"Low sales\"\n",
    "    else:\n",
    "        return \"Middle sales\"\n",
    "    \n",
    "df[\"totalSalesAcquiredClass\"] = df.Total_Sales_Acquired.apply(salary_class)\n",
    "\n",
    "df[[\"Emp_ID\", \"Total_Sales_Acquired\", \"totalSalesAcquiredClass\"]].sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age vs Salary** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for choosing this relationship: \n",
    "We wanted to examine if older workers earn higher salaries than younger workers, due to the fact that they have more experience in the workforce.\n",
    "\n",
    "Relationship: \n",
    "There is no clear relationship between the two variables. According to the scatter plot, most of the points are concentrated around the salary range of $40,000 - $80,000, and is independent of the ages of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xs = df.Salary\n",
    "ys = df.Age\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Plot of Age vs Salary\", fontsize=15)\n",
    "plt.xlabel(\"Salary\", fontsize=12)\n",
    "plt.ylabel(\"Age\", fontsize=12)\n",
    "#plt.yticks([1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(xs, ys)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(xs, ys)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.var(), ys.var() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City vs Salary** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for choosing this relationship: \n",
    "We wanted to examine if people living in the city affects how much they earn.\n",
    "\n",
    "Relationship: \n",
    "There is no clear relationship between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.City, df.salaryClass, normalize=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Designation vs Salary** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for choosing the relationship:\n",
    "We wanted to examine if a higher designation equates to earning higher salaries.\n",
    "\n",
    "Relationship:\n",
    "Our hypothesis is generally true. People who are of designation 5 have approximately 58.9% if them earning very high salaries. Conversely, those who are of designations 1 and 2 mainly earn low to middle salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Designation, df.salaryClass, normalize=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education vs Join Designation** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Education, df.Join_Designation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age vs Designation** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.Age\n",
    "ys = df.Designation\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Plot of Age vs Designation\", fontsize=15)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Designation\", fontsize=12)\n",
    "plt.yticks([1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City vs (Designation-JD)** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.City\n",
    "ys = df.Designation - df.Join_Designation\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Plot of City vs Change In Designation\", fontsize=15)\n",
    "plt.xlabel(\"City name\", fontsize=12)\n",
    "plt.ylabel(\"Change In Designation\", fontsize=12)\n",
    "plt.yticks([0,1,2,3,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(LWD-JD) vs (Designation-JD)** <a id=\"p3b11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.Last_Work_Date - df.Join_Date\n",
    "ys = df.Designation - df.Join_Designation\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Plot of Time Worked vs Change In Designation\", fontsize=15)\n",
    "plt.xlabel(\"Time Worked (years)\", fontsize=12)\n",
    "plt.ylabel(\"Change In Designation\", fontsize=12)\n",
    "plt.yticks([0,1,2,3,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Back)](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender vs Sales.\n",
    "-I am simply gonna use the same sales class above to do the comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Total_Sales_Acquired\"].quantile(0.25)\n",
    "Q2 = df[\"Total_Sales_Acquired\"].quantile(0.50)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)\n",
    "#lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def salary_class(n):   \n",
    "    if n > upper:\n",
    "        return \"Very high sales\"\n",
    "    elif n > Q3:\n",
    "        return \"High sales\"\n",
    "    elif n < Q2:\n",
    "        return \"Low sales\"\n",
    "    else:\n",
    "        return \"Middle sales\"\n",
    "    \n",
    "df[\"totalSalesAcquiredClass\"] = df.Total_Sales_Acquired.apply(salary_class)\n",
    "\n",
    "table = pd.crosstab(df.Gender, df.totalSalesAcquiredClass)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm = pd.crosstab(df.Gender, df.totalSalesAcquiredClass, normalize=\"index\")\n",
    "table_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = table[\"High sales\"][\"Female\"] + table[\"Middle sales\"][\"Female\"] + table[\"Low sales\"][\"Female\"] + table[\"Very high sales\"][\"Female\"] + table[\"High sales\"][\"Male\"] + table[\"Middle sales\"][\"Male\"] + table[\"Low sales\"][\"Male\"] + table[\"Very high sales\"][\"Male\"]\n",
    "Female_AtLeastHigh = table[\"High sales\"][\"Female\"] + table[\"Very high sales\"][\"Female\"]\n",
    "Male_AtLeastHigh = table[\"High sales\"][\"Male\"] + table[\"Very high sales\"][\"Male\"]\n",
    "AtLeastHigh = table[\"High sales\"][\"Female\"] + table[\"Very high sales\"][\"Female\"] + table[\"High sales\"][\"Male\"] + table[\"Very high sales\"][\"Male\"]\n",
    "Females = table[\"High sales\"][\"Female\"] + table[\"Middle sales\"][\"Female\"] + table[\"Low sales\"][\"Female\"] + table[\"Very high sales\"][\"Female\"]\n",
    "Males = table[\"High sales\"][\"Male\"] + table[\"Middle sales\"][\"Male\"] + table[\"Low sales\"][\"Male\"] + table[\"Very high sales\"][\"Male\"]\n",
    "\n",
    "print(f\"Probability(AtLeastHigh)={AtLeastHigh/workers}\")\n",
    "print(f\"Probability(AtLeastHigh | Female)={Female_AtLeastHigh/Females}\")\n",
    "print(f\"Probability(AtLeastHigh | Male)={Male_AtLeastHigh/Males}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence given that the Probability(AtLeastHigh) , that is to say sales is of class \"High sales\" and \"Very high sales\" is actually 0.25.\n",
    "While Probability(AtLeastHigh | Female) is also roughly 0.25 being actually 0.25257731958762886\n",
    "and\n",
    "Probability(AtLeastHigh | Male) is also roughly 0.25 , with the probability actually being 0.24821173104434907\n",
    "We can safely conclude that Sales is independent of Gender and that being Male or Female will not affect the TotalSalesAcquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will simply do the City vs Sales\n",
    "#Using the same classification as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Total_Sales_Acquired\"].quantile(0.25)\n",
    "Q2 = df[\"Total_Sales_Acquired\"].quantile(0.50)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)\n",
    "#lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def salary_class(n):   \n",
    "    if n > upper:\n",
    "        return \"Very high sales\"\n",
    "    elif n > Q3:\n",
    "        return \"High sales\"\n",
    "    elif n < Q2:\n",
    "        return \"Low sales\"\n",
    "    else:\n",
    "        return \"Middle sales\"\n",
    "    \n",
    "df[\"totalSalesAcquiredClass\"] = df.Total_Sales_Acquired.apply(salary_class)\n",
    "tableCity = pd.crosstab(df.City, df.totalSalesAcquiredClass)\n",
    "tableCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What I am gonna do is basically, since there is too many cities, I will simply compare probability of the Very High sales vs the probability of very high sales given a specific city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let the total data of workers in all the cities be df.City.count()\n",
    "AllCitiesTotal = df.City.count()\n",
    "VeryHighSalesNo = tableCity[\"Very high sales\"][\"C1\"] + tableCity[\"Very high sales\"][\"C2\"] + tableCity[\"Very high sales\"][\"C3\"] + tableCity[\"Very high sales\"][\"C4\"] + tableCity[\"Very high sales\"][\"C5\"] + tableCity[\"Very high sales\"][\"C6\"] + tableCity[\"Very high sales\"][\"C7\"] + tableCity[\"Very high sales\"][\"C8\"] + tableCity[\"Very high sales\"][\"C9\"] + tableCity[\"Very high sales\"][\"C10\"] + tableCity[\"Very high sales\"][\"C11\"] + tableCity[\"Very high sales\"][\"C12\"] + tableCity[\"Very high sales\"][\"C13\"] + tableCity[\"Very high sales\"][\"C14\"] + tableCity[\"Very high sales\"][\"C15\"] + tableCity[\"Very high sales\"][\"C16\"] + tableCity[\"Very high sales\"][\"C17\"] + tableCity[\"Very high sales\"][\"C18\"] + tableCity[\"Very high sales\"][\"C19\"] + tableCity[\"Very high sales\"][\"C20\"] + tableCity[\"Very high sales\"][\"C21\"] + tableCity[\"Very high sales\"][\"C22\"] + tableCity[\"Very high sales\"][\"C23\"] + tableCity[\"Very high sales\"][\"C24\"] + tableCity[\"Very high sales\"][\"C25\"] + tableCity[\"Very high sales\"][\"C26\"] + tableCity[\"Very high sales\"][\"C27\"] + tableCity[\"Very high sales\"][\"C28\"] + tableCity[\"Very high sales\"][\"C29\"]\n",
    "AllCitiesTotal\n",
    "VeryHighSalesNo\n",
    "print(f\"Probability(Very high sales)={VeryHighSalesNo/AllCitiesTotal} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableCity_Norm = pd.crosstab(df.City, df.totalSalesAcquiredClass, normalize=\"index\")\n",
    "tableCity_Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check C20 for probability of veryHighSales\n",
    "C20VeryHighSales = tableCity_Norm[\"Very high sales\"][\"C20\"]\n",
    "C20VeryHighSales\n",
    "print(f\"Probability(Very high sales | C20 )={C20VeryHighSales} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the Probability(very high sales) is not the same as the Probability(Very high sales | C20 ), this seems to imply that there is some sort of dependency where the city will affect the probability of the TotalSalesAcquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will do (LastWorkingDate - JoinDate) vs Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], dayfirst=True)  \n",
    "\n",
    "df[\"Join_Day\"] = df['Join_Date'].dt.day\n",
    "df[\"Join_Month\"] = df['Join_Date'].dt.month\n",
    "df[\"Join_Year\"] = df['Join_Date'].dt.year\n",
    "\n",
    "df[\"Join_Day\"].describe()\n",
    "df[\"Join_Month\"].describe()\n",
    "df[\"Join_Year\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so apparently, all the columns are float, so I want to make them int to be able to do computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Join_Day\"] = df[\"Join_Day\"].astype(int)\n",
    "df[\"Join_Month\"] = df[\"Join_Month\"].astype(int)\n",
    "df[\"Join_Year\"] = df[\"Join_Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"JoinDateInDays\"] = df.apply(lambda row : (row.Join_Year * 365) + (row.Join_Month * 30) + (row.Join_Day) , axis=1)\n",
    "#At this point I am too tired and can't figure out a way to make month 28 , 30 or 31 days lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Work_Date'] = pd.to_datetime(df['Last_Work_Date'], dayfirst=True)  \n",
    "\n",
    "df[\"LWD_Day\"] = df['Last_Work_Date'].dt.day\n",
    "df[\"LWD_Month\"] = df['Last_Work_Date'].dt.month\n",
    "df[\"LWD_Year\"] = df['Last_Work_Date'].dt.year\n",
    "\n",
    "df[\"LWD_Day\"].describe()\n",
    "df[\"LWD_Month\"].describe()\n",
    "df[\"LWD_Year\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LWD_Day\"] = df[\"LWD_Day\"].astype(int)\n",
    "df[\"LWD_Month\"] = df[\"LWD_Month\"].astype(int)\n",
    "df[\"LWD_Year\"] = df[\"LWD_Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LastWorkDateInDays\"] = df.apply(lambda row : (row.LWD_Year * 365) + (row.LWD_Month * 30) + (row.LWD_Day) , axis=1)\n",
    "#At this point I am too tired and can't figure out a way to make month 28 , 30 or 31 days lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DaysWorked\"] = df.apply(lambda row : abs(row.LastWorkDateInDays - row.JoinDateInDays) , axis=1)\n",
    "#What is attribute error :( !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will just proceed as if there is no error for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.DaysWorked\n",
    "ys = df.Total_Sales_Acquired\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "plt.title(\"DaysWorked vs TotalSalesAcquired\", fontsize=15)\n",
    "plt.xlabel(\"DaysWorked\", fontsize=12)\n",
    "plt.ylabel(\"TotalSalesAcquired\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(xs,ys)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time_Worked\"] = df[\"Last_Work_Date\"] - df[\"Join_Date\"]\n",
    "# Convert Time_Worked from timedelta to number of days\n",
    "df[\"Time_Worked\"] = df[\"Time_Worked\"].dt.days\n",
    "\n",
    "df[[\"Emp_ID\",\"Last_Work_Date\",\"Join_Date\",\"Time_Worked\"]]\n",
    "\n",
    "xs = df.Time_Worked\n",
    "ys = df.Total_Sales_Acquired\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "plt.title(\"Time_Worked vs TotalSalesAcquired\", fontsize=15)\n",
    "plt.xlabel(\"Time_Worked\", fontsize=12)\n",
    "plt.ylabel(\"TotalSalesAcquired\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "corr1 = np.corrcoef(xs,ys)\n",
    "corr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the Correlation coefficient is more than 0.50 and quite close to 0.70, we can imply that the Time_Worked which is given by \n",
    "Last_Work_Date - Join_Date, has a strong correlation to the TotalSalesAcquired.\n",
    "Hence the Time_worked can affect the TotalSalesAcquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
