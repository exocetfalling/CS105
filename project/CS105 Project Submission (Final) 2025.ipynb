{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Singapore Management University<br>\n",
    "CS105 Statistical Thinking for Data Science, 2024/25 Term 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYBbWb-0Kc6H"
   },
   "source": [
    "# CS105 Group Project Submission (Final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Provide your team details, including section, team number, team members, and the name of the dataset. \n",
    "Complete all of the following sections. For any part requiring code to derive your answers, please create a code cell immediately below your response and run the code.\n",
    "To edit any markdown cell, double click the cell; after editing, execute the markdown cell to collapse it.\n",
    "\n",
    "Include both Part I and Part II to produce a self-contained notebook. You may fine-tune Part I codes and/or findings based on feedback received on Part I submission.\n",
    "<br>\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration\n",
    "\n",
    "<span style=\"color:red\">By submitting this notebook, we declare that **no part of this submission is generated by any AI tool**. We understand that AI-generated submissions will be considered as plagiarism, and just like other plagirisum cases, disciplinary actions will be imposed.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section:   G5\n",
    "#### Team:      T1\n",
    "#### Members:\n",
    "1. Zachary Tay\n",
    "2. Bryan Lee\n",
    "3. Ang Qi Long\n",
    "4. Jonathan Wong\n",
    "5. Swayam Jain\n",
    "\n",
    "#### Dataset: Employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('employee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"menu\"></a>\n",
    "#### Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Part 1: EDA](#phase1)\n",
    "1. [Overview of Dataset](#part1)\n",
    "2. [Data Pre-processing](#part2)\n",
    "3. [Exploratory Analysis and Visualization](#part3)\n",
    "### [Part 2: Modeling](#phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"phase1\"></a>\n",
    "## Part I: Exploratory Data Analysis (EDA) [8% of final grade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "### 1. Overview of dataset [15% of Part I]\n",
    "a. [Background](#part1a) <br>\n",
    "b. [Size](#part1b) <br>\n",
    "c. [Variables](#part1c)\n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** Summarise the background of the dataset [limited to 50 words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "This dataset contains <b>HR data of all employees under a sales team</b>. The data includes <b>personal and employment details</b>, <b>total career sales acquired</b> and <b>latest quarterly rating</b>. An employee’s data is <b>captured at the beginning of each month</b>, either <b>up to the latest month</b> (Dec 2017) or <b>when they quit</b>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b.** State the size of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size**\n",
    "- **Rows**: 2381\n",
    "- **Columns**: 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1c\"></a> [(Back)](#part1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** For each variable, describe what it represents and its data type (numerical or categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: The date when an employee's data is recorded \n",
    "\n",
    "**Emp_ID**\n",
    "- **Type**: Categorical (Nominal)<br>\n",
    "- **Info**: The unique ID of an employee\n",
    "\n",
    "**Age**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: The age of an employee\n",
    "  \n",
    "**Gender**\n",
    "- **Type**: Categorical (Nominal)<br>\n",
    "- **Info**: An employee’s gender (Male or Female)\n",
    "\n",
    "**City**\n",
    "- **Type**: Categorical (Nominal)<br>\n",
    "- **Info**: The city where an employee works in (C1, C2, ..., C29)\n",
    "\n",
    "**Education**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Highest education of an employee (College, Bachelor, Master)\n",
    "\n",
    "**Salary**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: Current salary of an employee, excluding bonus \n",
    "\n",
    "**Join_Date**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: The date when an employee joins the company\n",
    "\n",
    "**Last_Work_Date**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: The data when an employee leaves the company, otherwise empty if employee has not quit\n",
    "\n",
    "**Join_Designation**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Designation level when an employee joined the company (1, 2, 3, 4, 5)\n",
    "\n",
    "**Designation**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Current designation level of an employee (1, 2, 3, 4, 5)\n",
    "\n",
    "**Total_Sales_Accquired**\n",
    "- **Type**: Numerical (Discrete)<br>\n",
    "- **Info**: Total sales generated by an employee since joining the team\n",
    "\n",
    "**Quarterly_Rating**\n",
    "- **Type**: Categorical (Ordinal)<br>\n",
    "- **Info**: Last quarterly performance rating of an employee (1, 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Back)](#part1) <a id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "### 2. Data pre-processing [35% of Part I]\n",
    "a. [Missing Data](#part2a) <br>\n",
    "b. [Outlier](#part2b) <br>\n",
    "c. [Encoding](#part2c)                                   \n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** For each variable, determine the percentage of missing data. For any column with missing data, describe how you resolve the issue. Clearly state any assumption you made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable w/ Missing Data | Count | Percentage |\n",
    "| :---------------- | :------: | ----: |\n",
    "| Join_Date | 118 | 4.96% |\n",
    "| Last_Work_Date | 765 | 32.13% |\n",
    "| Join_Designation | 105 | 4.41% |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayMissing() :\n",
    "    missing_count = df.shape[0] - df.count()              # total rows - rows with non-null values\n",
    "    missing_percent = (missing_count / df.shape[0] * 100) # missing rows / total rows\n",
    "\n",
    "    missing_data = pd.DataFrame({'Count': missing_count, 'Percentage': round(missing_percent,2)})\n",
    "    missing_data = missing_data[missing_data['Count'] > 0]  # filter out variable w/o missing data\n",
    "\n",
    "    return missing_data\n",
    "\n",
    "displayMissing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Resolution**: Drop all rows with missing `Join_Date`\n",
    "- **Reason**: As data of an employee is updated every month, there is no past record to check for their join date. We therefore cannot reasonably ascertain when they joined the sales team. Additionally, as the duration of employement will impact other variables and the percentage of missing data is not too high (4.96%), we opted to drop these rows with missing `Join_Date`\n",
    "- **Assumption(s)**:\n",
    "    - Each employee will only have one Emp_ID unique to them\n",
    "    - An employee who had quit will not join the sales team again nor gain a new Emp_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Join_Date'], inplace = True)         # drop all rows with null values under Join_Date\n",
    "displayMissing()                                        # Join_Date count is 0 (LWD & JD are affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Resolution**: For rows with missing `Last_Work_Date`,\n",
    "    - If `Date` is before 1/12/2017, drop rows\n",
    "    - If `Date` is 1/12/2017, impute rows with 31/12/2017\n",
    "- **Reason**: \n",
    "    - For rows before Dec 2017, an older `Date` suggests that the employee is no longer with the sales team. The employee may quit on anyday within a given month and make any number of sales in that period too, thus affecting the other variables. As we again cannot reasonably ascertain when the employee quit and number of affected is not too high (24, 1.06%), we opted to drop these rows with missing 'Last_Work_Date`\n",
    "    - For rows during Dec 2017, `Last_Work_Date` being blank indicates that the employee has not quit in that given month. As such, we can state that the date they last worked (or are employed) is 31 Dec 2017 and opted to impute with this date.\n",
    "- **Assumption(s)**: \n",
    "    - There are no other employees will quit during Dec 2017 beyond those given in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "unknownLastDate = df[(df['Last_Work_Date'].isnull()) & (df['Date'] < '2017-12-01')].shape[0]\n",
    "print(\"Unknown Last Date:\", unknownLastDate, round(unknownLastDate / df.shape[0] * 100, 2), \"%\")\n",
    "\n",
    "stillWorking = df[(df['Last_Work_Date'].isnull()) & (df['Date'] == '2017-12-01')].shape[0]\n",
    "print(\"Still Working:\", stillWorking, round(stillWorking / df.shape[0] * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknownLastDate = df[(df['Last_Work_Date'].isnull()) & (df['Date'] < '2017-12-01')]     # splice out rows where Date is before Dec 2017\n",
    "df.drop(unknownLastDate.index, inplace=True)                                            # use index of unknownLastDate and drop row\n",
    "\n",
    "df.fillna({\"Last_Work_Date\": \"31/12/2017\"}, inplace=True)                               # impute rows of employees still working with sales team\n",
    "                                                                                        # with last day of month (31 Dec 2017)\n",
    "\n",
    "displayMissing()                                                                        # Last_Work_Date is 0 (JD affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Resolution**: For rows with missing `Join_Designation`, \n",
    "    - If `Designation == 1`, impute rows with 1\n",
    "    - If `Designation > 1`, drop these rows\n",
    "- **Reason**: \n",
    "    - As `Designation` captures the current designation level of an employee when their data was recorded, if current designation level is 1, then we can definitvely deduce that the `Join_Designation` is 1 too. \n",
    "    - For any higher current designation level than 1, we again cannot reasonably ascertain their initial designation level as it likely varies with other variables. As the number and percentage of rows missing data where `Designation > 1`  is not too high (78, 3.48%), we opted to drop these rows and impute those where where `Designation == 1` is 1 (22, 0.983%) with 1  \n",
    "- **Assumption(s)**: -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdIs1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] == 1)].shape[0]\n",
    "cdNot1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] != 1)].shape[0]\n",
    "\n",
    "print(\"(Current) Designation = 1:\", cdIs1, round(cdIs1 / df.shape[0] * 100, 3), \"%\")\n",
    "print(\"(Current) Designation > 1:\", cdNot1, round(cdNot1 / df.shape[0] * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdNot1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] != 1)]   # splice out rows where designation > 1\n",
    "df.drop(cdNot1.index, inplace=True)                                         # use index of cdNot1 and drop row\n",
    "# print(cdNot1.shape[0])\n",
    "\n",
    "cdIs1 = df[(df['Join_Designation'].isnull()) & (df['Designation'] == 1)]    # splice out rows where designation is 1\n",
    "# print(cdIs1.iloc[cdIs1[cdIs1[\"Emp_ID\"]==21].index])\n",
    "df.loc[cdIs1.index, \"Join_Designation\"] = 1                                 # use index of cdIs1 and impute row with 1\n",
    "# print(cdIs1.shape[0])\n",
    "# print(df.iloc[df[df[\"Emp_ID\"]==21].index])\n",
    "\n",
    "df['Join_Designation'] = df['Join_Designation'].astype(int)                 # convert imputed float (1.0) to int (1)\n",
    "# print(df.iloc[df[df[\"Emp_ID\"]==21].index])\n",
    "displayMissing()                                                            # Join_Designation count is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size after Cleaning**\n",
    "- **Rows**: 2161\n",
    "- **Columns**: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2b\"></a> [(Back)](#part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **b.** For each variable, identify outliers (if any) and describe how you resolve the issue. Clearly state any assumption you made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There exists 33 outlier rows with `Age` above upper bound.\n",
    "- **Resolution**: Remove the row with the outlier with the employee of the oldest age.\n",
    "- **Reason**: This outlier is siginficantly further away from the rest of the cluster\n",
    "- **Assumption(s)**: \n",
    "    - An employee is not forced to quit or retire once they reach a certain age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "Q1 = df[\"Age\"].quantile(0.25)\n",
    "Q3 = df[\"Age\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is 17 years old                \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is 49 years old\n",
    "\n",
    "below = df[df['Age'] <= lower].shape[0]\n",
    "above = df[df['Age'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows below lower bound ({int(lower)}): {below}\")\n",
    "print(f\"Rows below upper bound ({int(upper)}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Age\"]].boxplot()\n",
    "plt.title(\"Age\")\n",
    "plt.ylabel(\"Years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the oldest person\n",
    "max_age = df.Age.max()\n",
    "age_outlier = df[df[\"Age\"] == max_age]\n",
    "age_outlier\n",
    "df.drop(age_outlier.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There exists 50 outlier rows with `Salary` above upper bound.\n",
    "- **Resolution**:\n",
    "    - Drop the 3 outliers separated from the cluster\n",
    "    - Keep the outliers within the cluster\n",
    "- **Reason**:\n",
    "    - As there is only 3 such outliers that are much further away from the rest of the points, we opted to drop them.\n",
    "    - Likely corresponds to employee with higher designation level. As such, we should keep these outliers for our data analysis\n",
    "- **Assumption(s)**: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers for salary\n",
    "\n",
    "Q1 = df[\"Salary\"].quantile(0.25)\n",
    "Q3 = df[\"Salary\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is $-16409.25                \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is $129844.75\n",
    "\n",
    "below = df[df['Salary'] <= lower].shape[0]\n",
    "above = df[df['Salary'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows below lower bound (${lower}): {below}\")\n",
    "print(f\"Rows below upper bound (${upper}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Salary\"]].boxplot()\n",
    "plt.ylabel(\"Dollars ($)\")\n",
    "plt.show()\n",
    "\n",
    "df.sort_values('Salary', ascending=False)[[\"Emp_ID\", \"Salary\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 3 outliers\n",
    "top_3_outliers = df.sort_values(\"Salary\", ascending=False).head(3)\n",
    "df.drop(top_3_outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There exists 256 rows where the month of `Last_Work_Date` is different from that of `Date`.\n",
    "- **Resolution**: Keep these outlier rows\n",
    "- **Reason**: It is possible for an employee to quit days after when they last worked. As the number of rows is large (256), we opted to keep these outliers.\n",
    "- **Assumption(s)**:\n",
    "    - An employee may officially quit after a maximum of 3 days after they last worked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Work_Date'] = pd.to_datetime(df['Last_Work_Date'], dayfirst=True)\n",
    "conditions = [['2015-12-31', '2016-01-01'], ['2016-01-31', '2016-02-01'], ['2016-02-29', '2016-03-01'], ['2016-03-31', '2016-04-01'], \n",
    "              ['2016-04-30', '2016-05-01'], ['2016-05-31', '2016-06-01'], ['2016-06-30', '2016-07-01'], ['2016-07-31', '2016-08-01'], \n",
    "              ['2016-08-31', '2016-09-01'], ['2016-09-30', '2016-10-01'], ['2016-10-31', '2016-11-01'], ['2016-11-30', '2016-12-01'], \n",
    "              ['2016-12-31', '2017-01-01'], ['2017-01-31', '2017-02-01'], ['2017-02-28', '2017-03-01'], ['2017-03-31', '2017-04-01'], \n",
    "              ['2017-04-30', '2017-05-01'], ['2017-05-31', '2017-06-01'], ['2017-06-30', '2017-07-01'], ['2017-07-31', '2017-08-01'], \n",
    "              ['2017-08-31', '2017-09-01'], ['2017-09-30', '2017-10-01'], ['2017-10-31', '2017-11-01'], ['2017-11-30', '2017-12-01']]\n",
    "    \n",
    "total = 0\n",
    "for lwd, rd in conditions:\n",
    "    conflicts = df[df[\"Last_Work_Date\"] <= lwd]\n",
    "    conflicts = conflicts[conflicts[\"Date\"] == rd]\n",
    "\n",
    "    count = conflicts.sort_values(by=\"Last_Work_Date\").shape[0]\n",
    "    earliest_date = conflicts.Last_Work_Date.min(0).strftime('%d %b')\n",
    "    latest_date = conflicts.Last_Work_Date.max(0).strftime('%d %b')\n",
    "\n",
    "    print(f\"Date: {rd} | Last work in previous month: {count}\")\n",
    "    print(f\" >>> From {earliest_date} to {latest_date}\")\n",
    "    total += count\n",
    "        \n",
    "print(\"\\nAffected Rows:\",total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Acquired**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There exists 10 rows with negative `Total_Sales_Acquired`.\n",
    "- **Resolution**: Drop such rows with negative `Total_Sales_Acquired`\n",
    "- **Reason**: Total sales acquired should minimally be 0, not negative. We should not absolute these negative values or impute with 0 as we cannot reasonably ascertain true total sales.\n",
    "- **Assumption(s)**:\n",
    "    - Dataset does not keep track whether an employee caused a loss of sales\n",
    "\n",
    "There exists 307 outlier rows with `Total_Sales_Acquired` above upper bound.\n",
    "- **Resolution**: Drop the top 3 rows that have outliers.\n",
    "- **Reason**: These outliers are siginficantly further away from the rest of the data points, hence, we have decided to drop them. \n",
    "- **Assumption(s)**: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Total_Sales_Acquired\"].quantile(0.25)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)\n",
    "lower = Q1 - 1.5 * (Q3-Q1)                          # lower bound is                 \n",
    "upper = Q3 + 1.5 * (Q3-Q1)                          # upper bound is \n",
    "\n",
    "negative = df[df['Total_Sales_Acquired'] < 0].shape[0]\n",
    "below = df[df['Total_Sales_Acquired'] <= lower].shape[0]\n",
    "above = df[df['Total_Sales_Acquired'] >= upper].shape[0]\n",
    "\n",
    "print(f\"Rows with negative sales: {negative}\");\n",
    "print(f\"Rows below lower bound ({lower}): {below}\")\n",
    "print(f\"Rows below upper bound ({upper}): {above}\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Total_Sales_Acquired\"]].boxplot()\n",
    "plt.ylabel(\"Sales (x10^8)\")\n",
    "plt.show()\n",
    "\n",
    "df.sort_values('Total_Sales_Acquired', ascending=False)[[\"Emp_ID\", \"Total_Sales_Acquired\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with negative sales\n",
    "negativeSales = df[df['Total_Sales_Acquired'] < 0]  \n",
    "df.drop(negativeSales.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 3 outliers\n",
    "top_3_outliers = df.sort_values(\"Total_Sales_Acquired\", ascending=False).head(3)\n",
    "df.drop(top_3_outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size after Handling Outliers**\n",
    "- **Rows**: 2144\n",
    "- **Columns**: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f\"{n_rows} Rows\")\n",
    "print(f\"{n_cols} Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2c\"></a> [(Back)](#part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** For categorical variables, perform the necessary encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp ID, Join Designation, Designation, Quarterly Rating**\n",
    "\n",
    "These categorical variables are stored as `int` and therefore need not be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender**\n",
    "Binary (nominal) variable; To apply binary encoding \n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|Male|0|\n",
    "|Female|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoding = {\"Male\":0, \"Female\":1} \n",
    "df[\"Gender_Encoded\"] = df[\"Gender\"].map(gender_encoding)        # map Gender column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Gender\", \"Gender_Encoded\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City**\n",
    "Ordinal variable; To apply ordinal encoding\n",
    "\n",
    "Extract city number\n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|C1|1|\n",
    "|C2|2|\n",
    "|...|...|\n",
    "|C28|28|\n",
    "|C29|29|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoding = {\"C1\":1, \"C2\":2, \"C3\":3, \"C4\":4 ,\"C5\":5 ,\"C6\":6,\"C7\":7,\"C8\":8,\"C9\":9,\"C10\":10,\"C11\":11, \"C12\":12, \"C13\":13, \"C14\":14, \"C15\":15 ,\"C16\":16 ,\"C17\":17,\"C18\":18,\"C19\":19,\"C20\":20,\"C21\":21,\"C22\":22, \"C23\":23, \"C24\":24, \"C25\":25, \"C26\":26 ,\"C27\":27 ,\"C28\":28,\"C29\":29}\n",
    "\n",
    "df[\"City_Encoded\"] = df[\"City\"].map(city_encoding)              #map City column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"City\", \"City_Encoded\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education**\n",
    "Ordinal variable; To apply ordinal encoding\n",
    "|Value|Encoded|\n",
    "|:-:|:-:|\n",
    "|College|0|\n",
    "|Bachelor|1|\n",
    "|Master|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_encoding = {\"College\":0, \"Bachelor\":1, \"Master\":2} \n",
    "df[\"Education_Encoded\"] = df[\"Education\"].map(education_encoding)  # map Gender column using encoding\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Education\", \"Education_Encoded\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice month and year from `Date`<br>\n",
    "Day is not needed as data is always captured at beginning of each month (i.e. 1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)  # already converted above\n",
    "\n",
    "df[\"Recorded_Month\"] = df['Date'].dt.month\n",
    "df[\"Recorded_Year\"] = df['Date'].dt.year\n",
    "\n",
    "df[[\"Date\", \"Emp_ID\", \"Recorded_Month\", \"Recorded_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice day, month and year from `Join_Date`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], dayfirst=True)  \n",
    "\n",
    "df[\"Join_Day\"] = df['Join_Date'].dt.day\n",
    "df[\"Join_Month\"] = df['Join_Date'].dt.month\n",
    "df[\"Join_Year\"] = df['Join_Date'].dt.year\n",
    "\n",
    "df[[\"Emp_ID\", \"Join_Date\", \"Join_Day\", \"Join_Month\", \"Join_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**\n",
    "Convert date string to pandas Timestamp <br>\n",
    "Splice day, month and year from `Last_Work_Date`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Last_Work_Date'] = pd.to_datetime(df['Last_Work_Date'], dayfirst=True)    # already converted above\n",
    "\n",
    "df[\"LWD_Day\"] = df['Last_Work_Date'].dt.day\n",
    "df[\"LWD_Month\"] = df['Last_Work_Date'].dt.month\n",
    "df[\"LWD_Year\"] = df['Last_Work_Date'].dt.year\n",
    "\n",
    "df[[\"Emp_ID\", \"Last_Work_Date\", \"LWD_Day\", \"LWD_Month\", \"LWD_Year\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Back)](#part2)\n",
    "<a id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3.\tExploratory analysis and visualization [50% of Part I]\n",
    "a. [Summary Statistics](#part3a) <br>\n",
    "b. [Visualisaton](#part3b) <br>\n",
    "c. [Bi-Variate Analysis](#part3c)\n",
    "\n",
    "_[(Back Top)](#menu)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a.** For each variable, provide relevant summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCategorical(column):\n",
    "    value_counts = df[column].value_counts()\n",
    "    percentage = (value_counts / df.shape[0]) * 100\n",
    "\n",
    "    col_data = pd.DataFrame({'Count': value_counts.values, 'Percentage': round(percentage, 2)})    \n",
    "    return col_data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp_ID**\n",
    "`Emp_ID` is an idenitifier and is unique across all 2144 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Emp_ID.nunique()\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"# unique employee IDs : {unique_count}\")\n",
    "print(f\"# rows : {n_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Age\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(\"Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.City.nunique()\n",
    "print(f\"# unique cities : {unique_count}\")\n",
    "\n",
    "value_counts = df[\"City\"].value_counts()                # Cannot sort normally by City(str) as \"C10\" < \"C2\" \n",
    "percentage = (value_counts / df.shape[0]) * 100\n",
    "\n",
    "col_data = pd.DataFrame({'Code':df[\"City_Encoded\"].value_counts().index,'Count': value_counts.values, 'Percentage': round(percentage, 2)})    \n",
    "col_data.sort_values(by=\"Code\").drop(columns=[\"Code\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Education.nunique()\n",
    "print(f\"# unique types of education : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Salary\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Join_Date.nunique()\n",
    "print(f\"# unique join dates : {unique_count}\")\n",
    "print()\n",
    "\n",
    "classes = df.Join_Date.unique()\n",
    "print(f\"Values of join dates : {classes}\")\n",
    "\n",
    "all_join_dates = df.Join_Date.mode()[0]  # note that .mode() returns a series so we need to access the first element using [0]\n",
    "df.Join_Date.value_counts()  # do a count to verify the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Last_Work_Date.nunique()\n",
    "print(f\"# unique last work dates : {unique_count}\")\n",
    "print()\n",
    "\n",
    "classes = df.Last_Work_Date.unique()\n",
    "print(f\"Values of last work dates : {classes}\")\n",
    "\n",
    "all_join_dates = df.Last_Work_Date.mode()[0]  # note that .mode() returns a series so we need to access the first element using [0]\n",
    "df.Last_Work_Date.value_counts()  # do a count to verify the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Join_Designation.nunique()\n",
    "print(f\"# unique types of join designations : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Join_Designation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Designation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Designation.nunique()\n",
    "print(f\"# unique types of designations : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Designation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Acquired**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Total_Sales_Acquired\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quarterly Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df.Quarterly_Rating.nunique()\n",
    "print(f\"# unique types of ratings : {unique_count}\")\n",
    "\n",
    "displayCategorical(\"Quarterly_Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3b\"></a> [(Back)](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b.** For each variable, provide an appropriate visualisation depicting the distribution of its values, and summarize any key observation(s) you made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Date** <a id=\"p3b1\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - Dec 2017 has the most data recorded as it includes those of employees that are still working (663) and have quit (72)\n",
    "    - Other dates being non-zero are due to employees who had quit within that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stillWorking = df[(df['Last_Work_Date']==\"31/12/2017\")].shape[0]\n",
    "dec2017 = df[(df['Date']==\"2017-12-01\")].shape[0]\n",
    "print(f\"Still Working in Dec 2017: {stillWorking}\")\n",
    "print(f\"Quit in Dec 2017: {dec2017-stillWorking}\")\n",
    "\n",
    "date_data = df[\"Date\"].value_counts(normalize=False)\n",
    "date_level = date_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(date_level, date_data, width=20)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Date\", fontsize=15)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.xticks(date_level, date_level.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Emp ID** <a id=\"p3b2\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - Interval between Emp_ID is not always 1, possibly suggesting a loss of data for these employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count_emp = df.Emp_ID.nunique()\n",
    "n_rows = df.shape[0]\n",
    "\n",
    "print(f\"# Total unique Emp_ID : {unique_count_emp}\")\n",
    "print(f\"# Total Rows : {n_rows}\")\n",
    "\n",
    "df[df[\"Emp_ID\"] < 500].Emp_ID.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age** <a id=\"p3b3\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution of Age is slightly right-skewed (more data above median)\n",
    "    - Most age of employess are within range of 30 to 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Age\"]].boxplot()\n",
    "plt.title(\"Age\", fontsize=15)\n",
    "plt.ylabel(\"Years\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Age\", fontsize=15)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Age\"].hist(bins=35)                         # max age:55, min age: 21\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gender** <a id=\"p3b4\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - There have been more males employees (59%) than female employees (41%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = df[\"Gender\"].value_counts(normalize=False)\n",
    "gender_level = gender_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(gender_level, gender_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Gender\", fontsize=15)\n",
    "plt.xlabel(\"Gender\", fontsize=12)\n",
    "# plt.xticks(gender_level, ['Male', 'Female'])\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **City** <a id=\"p3b5\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - City C20 has had the greatest number of employees, suggesting it is a significant location\n",
    "    - The distribution across the other 28 cities appears relatively uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = df[\"City_Encoded\"].value_counts(normalize=False)\n",
    "city_level = city_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(city_level, city_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Cities\", fontsize=15)\n",
    "plt.xlabel(\"City No. \", fontsize=12)\n",
    "plt.xticks(range(1, 30))\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Education** <a id=\"p3b6\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution across the 3 education levels is balanced, with College having a slightly lower count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_data = df[\"Education\"].value_counts(normalize=False)\n",
    "education_level = education_data.index\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "bars = plt.bar(education_level, education_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Education\", fontsize=15)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary** <a id=\"p3b7\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - The distribution of Salary is right-skewed (more data above median)\n",
    "    - There are many outliers above upper whisker, suggesting that a small portion of employees earn significantly higher salaries than the rest\n",
    "    - Most salaries are within range of $40 000 to $60 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Salary\"]].boxplot()\n",
    "plt.title(\"Salary\", fontsize=15)\n",
    "plt.ylabel(\"$\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Salary\", fontsize=15)\n",
    "plt.xlabel(\"Salary ($)\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Salary\"].hist(bins=50)                      # max salary: $153766; min salary: $10747; each bin ~$2860\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Date** <a id=\"p3b8\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - The highest count of hirings occurs near the end of the month (28th-109, 29th-91, 30th-103)\n",
    "    - The lowest count of hirings occurs just before days with highest count (24th-42, 26th-40, 27th-46)\n",
    "        <br><br>\n",
    "    - The frequency of hirings is at its lowest from Apr 2010 to Apr 2012\n",
    "    - There have hirings every month since May 2015, up to Dec 2017\n",
    "    - The number of hirings increased significantly during May 2015 (88)\n",
    "    - Since May 2015, the number of hirings are greater than those prior, except from Feb 2016 to May 2016\n",
    "    - May 2017 had the most hirings in a given month (104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_count = df.Join_Date.nunique()\n",
    "print(f\"# unique join dates  : {jd_count}\")\n",
    "\n",
    "# By Day\n",
    "cols = [\"Join_Day\", \"Join_Month\", \"Join_Year\"]\n",
    "xaxes = [np.arange(1,32,1), np.arange(1,13,1), np.arange(2010,2018,1)]\n",
    "labels = [\"Day\", \"Month\", \"Year\"]\n",
    "i = 0       #for i in range(3):\n",
    "\n",
    "date_data = df[cols[i]].value_counts(normalize=False)\n",
    "date_level = date_data.index\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "bars = plt.bar(date_level, date_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Join Date (\"+labels[i]+\")\", fontsize=15)\n",
    "plt.xlabel(labels[i], fontsize=12)\n",
    "plt.xticks(xaxes[i]) \n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# By Month, Year\n",
    "date_data = df.groupby(df[\"Join_Date\"].dt.to_period('M'))[\"Join_Date\"].count()\n",
    "date_level = date_data.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(date_level, date_data, width=20)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Join Date (Month, Year)\", fontsize=15)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.xticks(date_level, date_level.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Work Date** <a id=\"p3b9\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - The trend of `Last_Work_Date` is similar to that of `Date`\n",
    "    - The significant difference of 31 (Day graph) and Dec 2017 (Month, Year graph) is due to inclusion of people who did not quit during Dec 2017 (663)\n",
    "    - The number of employees who last worked on the 31st & in Dec 2017 and quit are 17 & 56 respectively\n",
    "    <br><br>\n",
    "    - The highest & lowest **day** employees last worked are 29th & 26th respectively\n",
    "    - In 2016, the highest & lowest **month** employees last worked are May & Jul respectively\n",
    "    - In 2017, the highest & lowest **month** employees last worked are Jul & Aug respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwd_count = df.Last_Work_Date.nunique()\n",
    "print(f\"# unique last work date : {lwd_count}\\n\")\n",
    "\n",
    "stillWorking = df[(df['Last_Work_Date']==\"31/12/2017\")].shape[0]\n",
    "print(f\"Still Working in Dec 2017: {stillWorking}\")\n",
    "\n",
    "# By Day\n",
    "cols = [\"LWD_Day\", \"LWD_Month\", \"LWD_Year\"]\n",
    "xaxes = [np.arange(1,32,1), np.arange(1,13,1), np.arange(2015,2018,1)]\n",
    "labels = [\"Day\", \"Month\", \"Year\"]\n",
    "i = 0           # for i in range(len(col)):\n",
    "\n",
    "date_data = df[cols[i]].value_counts(normalize=False)\n",
    "date_level = date_data.index\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "bars = plt.bar(date_level, date_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Last Work Date (\"+labels[i]+\")\", fontsize=15)\n",
    "plt.xlabel(labels[i], fontsize=12)\n",
    "plt.xticks(xaxes[i]) \n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# By Month, Year\n",
    "date_data = df.groupby(df[\"Last_Work_Date\"].dt.to_period('M'))[\"Last_Work_Date\"].count()\n",
    "date_level = date_data.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(date_level, date_data, width=20)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height()}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Last Work Date (Month, Year)\", fontsize=15)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.xticks(date_level, date_level.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(from above, for comparison)_\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join Designation** <a id=\"p3b10\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - Employees rarely join with designation level 4 or 5 (1.95%)\n",
    "    - An employee mostly likely joins with designation level 1 (44.21%)\n",
    "    - For each subsequent designation level, the employee count at that designation level decreases, with a significant drop between level 3 and 4 \n",
    "\n",
    "#### **Designation** <a id=\"p3b11\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - There is a significant drop in the number of employees at level 1 (11.81%), suggesting a quarter of employees at level 1 were promoted\n",
    "    - All other designation levels (2-5) have increased while following a similar trend as Join_Designation \n",
    "    - Designation level 3 has the greatest jump (5.02%)\n",
    "    - Designation level 5 is still the smallest (0.98%), suggesting it is difficult to be promoted to level 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5)) \n",
    "\n",
    "jd_data = df[\"Join_Designation\"].value_counts(normalize=True)\n",
    "bars1 = plt.bar(jd_data.index - 0.2, jd_data, 0.4, label = 'First Joined') \n",
    "\n",
    "for bar in bars1:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "cd_data = df[\"Designation\"].value_counts(normalize=True)\n",
    "bars2 = plt.bar(cd_data.index + 0.2, cd_data, 0.4, label = 'Latest') \n",
    "  \n",
    "for bar in bars2:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Designation Level\", fontsize=12) \n",
    "plt.ylabel(\"Percentage\", fontsize=12)  \n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "plt.legend() \n",
    "plt.title(\"Employee's Designation\", fontsize=15)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Sales Accquired** <a id=\"p3b12\"></a>\n",
    "- **Key Observation(s)**:\n",
    "    - A significant number of employees (653) acquired 0 total sales such that the lower quantile and lower bound are both 0 & is observed in the normalised distribution\n",
    "    - Among the outlier data\n",
    "        - The majority are concentrated between upper bound (0.1x10^8) and 0.4x10^8 total sales\n",
    "        - There is another grouping between 0.5x10^8 and 0.6x10^8 total sales\n",
    "    - The distribution of Total Sales Accquired is right-skewed (more data above median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(20,5))\n",
    "df[[\"Total_Sales_Acquired\"]].boxplot()\n",
    "plt.title(\"Total Sales Acquired\", fontsize=15)\n",
    "plt.ylabel(\"Sales (x10^8)\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Distribution by Total Sales Acquired\", fontsize=15)\n",
    "plt.xlabel(\"Sales (x10^8)\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "df[\"Total_Sales_Acquired\"].hist(bins=50)    \n",
    "plt.show()\n",
    "\n",
    "# Log1p Histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Normalised Distribution by Total Sales Acquired\", fontsize=15)\n",
    "plt.xlabel(\"Sales (x10^8)\", fontsize=12)\n",
    "plt.ylabel(\"Num. of Employees\", fontsize=12)\n",
    "log_totalSalesAcquired = np.log1p(df.Total_Sales_Acquired)\n",
    "log_totalSalesAcquired.hist(bins=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quarterly Rating** <a id=\"p3b13\"></a>\n",
    "- **Key Observation(s)**: \n",
    "    - Follows a logarithmic decrease, with a significant drop between rating 1 and 2\n",
    "    - The majority of employees are given a quarterly rating of 1, emphasising it is difficult to attain a higher rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_data = df[\"Quarterly_Rating\"].value_counts(normalize=True)\n",
    "qr_level = qr_data.index\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "bars = plt.bar(qr_level, qr_data)\n",
    "\n",
    "for bar in bars:                               \n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1%}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "plt.title(\"Employees' Quarterly Rating\", fontsize=15)\n",
    "plt.xlabel(\"Quarterly Rating\", fontsize=10)\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.ylabel(\"Percentage\", fontsize=10)\n",
    "plt.yticks(np.arange(0,0.9,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3c\"></a> [(Back)](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c.** Perform bi-variate analysis on the variables. You do not need to present the analysis of every pair of variables; only focus on the pairs you believe are worth investigating and explain. For each pair, describe the relationship between the two variables. Use appropriate statistical methods and/or visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Age Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We want to investigate whether an employee's age affects/is affected by other categorical variables\n",
    "    - `Basic` -> Total sales that falls before 25th quantile<br>\n",
    "    - `Moderate` -> Total sales that falls within interquartile range<br>\n",
    "    - `High` -> Total sales that falls with 75th quantile and top whisker<br>\n",
    "    - `Elite` -> Total sales that falls after top whisker<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Age\"].quantile(0.25)\n",
    "Q3 = df[\"Age\"].quantile(0.75)\n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def age_class(n):\n",
    "    if n > upper:\n",
    "        return \"Oldest\"\n",
    "    elif n > Q3:\n",
    "        return \"Older\"\n",
    "    elif n < Q1:\n",
    "        return \"Younger\"\n",
    "    else:\n",
    "        return \"Average\"\n",
    "    \n",
    "df[\"ageClass\"] = df.Age.apply(age_class)\n",
    "# df[[\"Emp_ID\", \"Age\", \"ageClass\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salary Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We want to investigate whether an employee's salary affects/is affected by other categorical variables\n",
    "    - `Low` -> Salaries that falls before 25th quantile<br>\n",
    "    - `Average` -> Salaries that falls within interquartile range<br>\n",
    "    - `High` -> Salaries that falls with 75th quantile and top whisker<br>\n",
    "    - `Elite` -> Salaries that falls after top whisker<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Salary\"].quantile(0.25)\n",
    "Q3 = df[\"Salary\"].quantile(0.75)            \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def salary_class(n):  \n",
    "    if n > upper:\n",
    "        return \"Elite\"\n",
    "    elif n > Q3:\n",
    "        return \"High\"\n",
    "    elif n < Q1:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Average\"\n",
    "    \n",
    "df[\"salaryClass\"] = df.Salary.apply(salary_class)\n",
    "# df[[\"Emp_ID\", \"Salary\", \"salaryClass\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Time Worked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We want to compute the number of days that an employee has worked for the sales team as it is more meaningful and useful to analyse its relationship with other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time_Worked\"] = df[\"Last_Work_Date\"] - df[\"Join_Date\"]\n",
    "df[\"Time_Worked\"] = df[\"Time_Worked\"].dt.days   # Convert Time_Worked from timedelta to number of days\n",
    "# df[[\"Join_Date\", \"Last_Work_Date\", \"Time_Worked\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Time Worked Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We also want to categorise an employee's tenure to investigate its effects on other categorical variables\n",
    "    - `Newcomer` -> Days employee has worked that falls before 25th quantile<br>\n",
    "    - `Experienced` -> Days employee has worked that falls within interquartile range<br>\n",
    "    - `Tenured` -> Days employee has worked that falls with 75th quantile and top whisker<br>\n",
    "    - `Veteran` -> Days employee has worked that falls after top whisker<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[\"Time_Worked\"].quantile(0.25)\n",
    "Q3 = df[\"Time_Worked\"].quantile(0.75)    \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def tenure_class(n):  \n",
    "    if n > upper:\n",
    "        return \"Veteran\"\n",
    "    elif n > Q3:\n",
    "        return \"Tenured\"\n",
    "    elif n < Q1:\n",
    "        return \"Newcomer\"\n",
    "    else:\n",
    "        return \"Experienced\"\n",
    "    \n",
    "df[\"timeWorkedClass\"] = df.Time_Worked.apply(tenure_class)\n",
    "# df[[\"Emp_ID\", \"Time_Worked\", \"timeWorkedClass\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Promotion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We want to check whether an employee has promoted from their initial designation and investigate whether this affects other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Promotion\"] = df[\"Designation\"] - df[\"Join_Designation\"]\n",
    "# df[[\"Emp_ID\",\"Join_Designation\", \"Designation\", \"Promotion\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sales Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Reason**: We want to investigate whether the total sales acquired by an employee affects/is affected by other categorical variables\n",
    "    - `Basic` -> Total sales that falls before 50th quantile<br>\n",
    "    - `Moderate` -> Total sales that falls within interquartile range<br>\n",
    "    - `High` -> Total sales that falls with 75th quantile and top whisker<br>\n",
    "    - `Elite` -> Total sales that falls after top whisker<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2 = df[\"Total_Sales_Acquired\"].quantile(0.5)\n",
    "Q3 = df[\"Total_Sales_Acquired\"].quantile(0.75)            \n",
    "upper = Q3 + 1.5 * (Q3-Q1) \n",
    "\n",
    "def sales_class(n): \n",
    "    if n > upper:\n",
    "        return \"Elite\"\n",
    "    elif n > Q3:\n",
    "        return \"High\"\n",
    "    elif n < Q2:\n",
    "        return \"Basic\"\n",
    "    else:\n",
    "        return \"Moderate\"\n",
    "    \n",
    "df[\"totalSalesAcquiredClass\"] = df.Total_Sales_Acquired.apply(sales_class)\n",
    "# df[[\"Emp_ID\", \"Total_Sales_Acquired\", \"totalSalesAcquiredClass\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Helper Functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCP_Col(X, table, total):\n",
    "    count = 0\n",
    "\n",
    "    for index in table.index:\n",
    "        count += table.at[index, X]\n",
    "\n",
    "    return count/total\n",
    "\n",
    "def UCP_Row(Y, table, total):\n",
    "    count = 0\n",
    "\n",
    "    for col in table.columns:\n",
    "        count += table.at[Y, col]\n",
    "\n",
    "    return count/total\n",
    "\n",
    "def displayProb(cols, rows, table_v, table_n, col_label, row_label):\n",
    "    for y in rows:\n",
    "        prob_y = UCP_Col(y, table_v, df.shape[0])\n",
    "        print(f\"P({row_label}={y}) = {prob_y}\")\n",
    "\n",
    "        for x in cols:\n",
    "            prob_y_given_x = table_n.at[x,y]\n",
    "            print(f\" > P({row_label}={y} | {col_label}={x}) = {prob_y_given_x}\")\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Age vs Salary**\n",
    "- **Explanation**: We wanted to examine if older workers earn higher salaries than younger workers, due to the fact that they have more experience in the workforce.\n",
    "\n",
    "- **Relationship**: \n",
    "    - As the correlation coefficient is 0.200, it suggests both are **dependent** and has **a positive correlation between both variables** - the older an employee is, the greater their expected salary is\n",
    "\n",
    "    - However, as the correlation coefficient is **not close to 1**, it implies that an employee's age is **not the sole factor** in determining their salary.\n",
    "\n",
    "    - Employees are most likely to have a salary between $20 000 to $60 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.Salary\n",
    "ys = df.Age\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Plot of Age vs Salary\", fontsize=15)\n",
    "plt.xlabel(\"Salary\", fontsize=12)\n",
    "plt.ylabel(\"Age\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_Age_Sal = np.corrcoef(xs, ys)[0][1]\n",
    "cov_Age_Salary = np.cov(xs, ys)[0][1]\n",
    "var_Sal = xs.var()\n",
    "var_Age = ys.var() \n",
    "\n",
    "print(f\"ρ                = {corr_Age_Sal}\")       #Correlation Coefficient; p=0 -> independent\n",
    "print(f\"Cov(Age, Salary) = {cov_Age_Salary}\")     #Cov(X,Y) = Cov(Y,X)\n",
    "print(f\"Var(Age)         = {var_Age}\")\n",
    "print(f\"Var(Salary)      = {var_Sal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. City vs Salary**\n",
    "- **Explanation**: We wanted to examine if the city employee works in affects how much they earn.\n",
    "- **Relationship**: \n",
    "    - We can conclude that the **salary of an employee is generally dependent of the city an employee works in** as conditional probability is quite different as unconditional probability\n",
    "        - ```P(Salary = Low | City = C11)``` and ```P(Salary = Low | Gender = C4)``` is different to ```P(Salary = Low)```\n",
    "            - 9.8% and 37.5% different to 25% \n",
    "        - ```P(Salary = Average | City = C18)``` and ```P(Salary = Average | City = C11)``` is same/similar to ```P(Salary = Average)```\n",
    "            - 34.4% and 60.7% == 50% \n",
    "        - ```P(Salary = High | City = C16)``` and ```P(Salary = High | City = C12)``` is same/similar to ```P(Salary = High)```\n",
    "            - 13.3% and 30.6% == 22.9% \n",
    "        - ```P(Salary = Elite | City = C23)``` and ```P(Salary = Elite | City = C11)``` is same/similar to ```P(Salary = Elite)```\n",
    "            - 0% and 4.9% == 2.1% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value2 = pd.crosstab(df.City, df.salaryClass)\n",
    "table_norm2 = pd.crosstab(df.City, df.salaryClass, normalize=\"index\")\n",
    "\n",
    "display_values_2 = table_value2[[\"Low\", \"Average\", \"High\", \"Elite\"]]\n",
    "display_norm_2 = table_norm2[[\"Low\", \"Average\", \"High\", \"Elite\"]]\n",
    "\n",
    "display_values_2 = display_values_2.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "display_norm_2 = display_norm_2.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "\n",
    "display_values_2 = display_values_2.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "display_norm_2 = display_norm_2.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "\n",
    "display_values_2.set_index(\"City\")\n",
    "display_norm_2.set_index(\"City\")\n",
    "\n",
    "display(display_values_2)\n",
    "display(display_norm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P(Salary=Low) = {UCP_Col(\"Low\", display_values_2, df.shape[0])}\")\n",
    "print(f\"P(Salary=Average) = {UCP_Col(\"Average\", display_values_2, df.shape[0])}\")\n",
    "print(f\"P(Salary=High) = {UCP_Col(\"High\", display_values_2, df.shape[0])}\")\n",
    "print(f\"P(Salary=Elite) = {UCP_Col(\"Elite\", display_values_2, df.shape[0])}\\n\")\n",
    "\n",
    "salaries = [\"Low\", \"Average\", \"High\", \"Elite\"]\n",
    "cities = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', \n",
    "          'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', \n",
    "          'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29'][::5]\n",
    "\n",
    "displayProb(cities, salaries, table_value2, table_norm2, \"City\", \"Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Designation vs Salary** \n",
    "- **Explanation**: We wanted to examine if a higher designation equates to earning higher salaries.\n",
    "\n",
    "- **Relationship**: \n",
    "    - We can conclude that the **salary of an employee is dependent on the employee's designation** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Salary = Low | Designation=1) = 54.0%``` is different from ```P(Salary = Low) = 25%``` \n",
    "        - ```P(Salary = Elite | Designation=5) = 58.8%``` is different from ```P(Salary = Elite) = 2.1%``` \n",
    "    - We can also conclude it is **not necessarily true** that **a higher designation level affects the likelihood of having a better salary**\n",
    "        - ```P(Salary = High | Designation=4) > P(Salary = High | Designation=3) and P(Salary = High | Designation=5)```\n",
    "            - _78.7% > 51.7% and 35.2%_\n",
    "    - Our hypothesis is generally true. People who are of designation 5 have approximately 58.9% if them earning very high salaries. Conversely, those who are of designations 1 and 2 mainly earn low to middle salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.crosstab(df.Designation, df.salaryClass, normalize=\"index\")\n",
    "result[[\"Low\", \"Average\", \"High\", \"Elite\"]]\n",
    "\n",
    "table_value3 = pd.crosstab(df.Designation, df.salaryClass)\n",
    "table_norm3 = pd.crosstab(df.Designation, df.salaryClass, normalize=\"index\")\n",
    "\n",
    "display(table_value3[[\"Low\", \"Average\", \"High\", \"Elite\"]])\n",
    "display(table_norm3[[\"Low\", \"Average\", \"High\", \"Elite\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = [\"Low\", \"Average\", \"High\", \"Elite\"]\n",
    "designations = [1,2,3,4,5]\n",
    "\n",
    "displayProb(designations, salaries, table_value3, table_norm3, \"Designation\", \"Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Education vs Join Designation**\n",
    "- **Explanation**: We wanted to examine if a higher education is associared with a higher join designation when the employee first joins the company.\n",
    "- **Relationship**:  \n",
    "    - We can conclude that **an employee's join designation is independent of the employee's education** as conditional probability is the same/similar to unconditional probability\n",
    "        - ```P(JoinDesignation=1 | Education=\"Master\") = 44.5%``` is same/similar to ```P(JoinDesignation=1) = 44.2%``` \n",
    "        - ```P(JoinDesignation=4 | Education=\"Bachelor\") = 1.2%``` is same/similar to ```P(JoinDesignation=4) = 1.6%``` \n",
    "\n",
    "    - Generally, it does not matter what each employee's education is.\n",
    "    - No matter which education one attains, majority of the employees start with a join designation of 1, followed by 2. \n",
    "    - Only a small proportion of employee starts joining the company with starting positions of 4 (34) or 5 (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value4 = pd.crosstab(df.Education, df.Join_Designation)\n",
    "table_norm4 = pd.crosstab(df.Education, df.Join_Designation, normalize=\"index\")\n",
    "\n",
    "display(table_value4)\n",
    "display(table_norm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educations = [\"College\", \"Bachelor\", \"Master\"]\n",
    "join_Designations = [1,2,3,4,5]\n",
    "\n",
    "displayProb(educations, join_Designations, table_value4, table_norm4, \"Education\", \"JoinDesignation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Age vs Designation**\n",
    "- **Explanation**: We wanted to test if older workers will be assigned higher designations, since they have been there for longer periods of time.\n",
    "- **Relationship**:\n",
    "    - We can conclude that **an employee's latest designation is dependent on their age** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Designation=1 | Age=\"Younger\") = 51.8%``` is different from ```P(Designation=1) = 32.5%``` \n",
    "        - ```P(Designation=4 | Age=\"Oldest\") = 1.4%``` is different from ```P(Designation=4) = 6.0%``` \n",
    "\n",
    "    - We can conclude that this trend is generally true.\n",
    "    - From our results, if we randomly select an employee of category \"older\" or \"oldest\", we get approximately 0.133 and 0.136 probabilities that he/she is of designation 4 or 5.\n",
    "    - Conversely, for if we randomly select an employee of category \"younger\" or \"average\", we get approximately 0.0160 and 0.0541 probabilities that he/she is of designation 4 or 5.\n",
    "    - It is possible that older workers have higher designations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value5 = pd.crosstab(df.ageClass, df.Designation)\n",
    "table_norm5 = pd.crosstab(df.ageClass, df.Designation, normalize=\"index\")\n",
    "\n",
    "display(table_value5)\n",
    "display(table_norm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designations = [1,2,3,4,5]\n",
    "ages = [\"Younger\", \"Average\", \"Older\", \"Oldest\"]\n",
    "\n",
    "displayProb(ages, designations, table_value5, table_norm5, \"Age\", \"Designation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm5.plot.bar(stacked=True)\n",
    "df[['Age','Designation']].boxplot(by='Designation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. City vs Promotion** \n",
    "- **Explanation**: We wanted to examine if people living in a certain cities get promoted faster than those living in other cities.\n",
    "- **Relationship**:\n",
    "    - We can conclude that **an employee's ability to promote is dependent on the city they work in** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Promotion=0 | City=C1) = 70.6%``` is different from ```P(Promotion=0) = 83.5%``` \n",
    "        - ```P(Promotion=1 | City=C1) = 12%``` is different from ```P(Promotion=1) = 8.9%``` \n",
    "\n",
    "    - The probability of an employee promote by 3 or 4 designation levels is about 0.0210\n",
    "    - The probabilities of an employee promote by 3 or 4 designation levels, given that they are from C1 and C4 are 0.0267 and 0.0278 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value6 = pd.crosstab(df.City, df.Promotion)\n",
    "table_norm6 = pd.crosstab(df.City, df.Promotion, normalize=\"index\")\n",
    "\n",
    "display_values_6 = table_value6.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "display_norm_6 = table_norm6.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "\n",
    "display_values_6 = display_values_6.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "display_norm_6 = display_norm_6.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "\n",
    "display_values_6.set_index(\"City\")\n",
    "display_norm_6.set_index(\"City\")\n",
    "\n",
    "display(display_values_6)\n",
    "display(display_norm_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P(Promotion=0) = {UCP_Col(0, display_values_6, df.shape[0])}\")\n",
    "print(f\"P(Promotion=1) = {UCP_Col(1, display_values_6, df.shape[0])}\")\n",
    "print(f\"P(Promotion=2) = {UCP_Col(2, display_values_6, df.shape[0])}\")\n",
    "print(f\"P(Promotion=3) = {UCP_Col(3, display_values_6, df.shape[0])}\")\n",
    "print(f\"P(Promotion=4) = {UCP_Col(4, display_values_6, df.shape[0])}\\n\")\n",
    "\n",
    "promotions = [0,1,2,3,4]\n",
    "cities = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', \n",
    "          'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', \n",
    "          'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29'][::3]\n",
    "\n",
    "displayProb(cities, promotions, table_value6, table_norm6, \"City\", \"Promotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Time Worked vs Promotion** \n",
    "- **Explanation**: We wanted to examine if people who work longer get promoted first.\n",
    "- **Relationship**: \n",
    "    - We can conclude that **an employee's ability to promote is dependent on how long they worked for** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Promotion=0 | TimeWorked=\"Veteran\") = 19.1%``` is different from ```P(Promotion=0) = 83.5%``` \n",
    "        - ```P(Promotion=1 | TimeWorked=\"Experienced\") = 2.0%``` is different from ```P(Promotion=1) = 8.9%```\n",
    "\n",
    "    - We can conclude if an employee promotes by 3 or 4 designation levels, it is much more likely that he/she is a tenured or veteran.\n",
    "    - The probability that an employee is a tenured or a veteran is 0.25 out of all the total employees.\n",
    "    - However, if one is of promotions 3 or 4, the chances that he/she is a tenured or veteran is 0.974 and 1.0 respectively.\n",
    "    - Hence, the hypothesis is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value7 = pd.crosstab(df.timeWorkedClass, df.Promotion)\n",
    "table_norm7 = pd.crosstab(df.timeWorkedClass, df.Promotion, normalize=\"index\")\n",
    "\n",
    "display(table_value7)\n",
    "display(table_norm7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotions = [0,1,2,3,4]\n",
    "timeWorkedClasses = [\"Newcomer\", \"Experienced\", \"Tenured\", \"Veteran\"]\n",
    "\n",
    "displayProb(timeWorkedClasses, promotions, table_value7, table_norm7, \"TimeWorked\", \"Promotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8. Gender vs Sales** \n",
    "- **Explanation**: We want to examine whether an employee's gender affects the sales acquired, possibly due to customer perception and such. This would help us better understand if gender plays a role in sales generated\n",
    "- **Relationship**:\n",
    "    - We can conclude that the **total sales generated is independent of the employee's gender** as conditional probability is the same as unconditional probability\n",
    "        - ```P(Sales = Basic | Gender = Female)``` and ```P(Sales = Basic | Gender = Male)``` is same/similar to ```P(Sales = Basic)```\n",
    "            - 48.4% and 51.1% == 50% \n",
    "        - ```P(Sales = Moderate | Gender = Female)``` and ```P(Sales = Moderate | Gender = Male)``` is same/similar to ```P(Sales = Moderate)```\n",
    "            - 26.3% and 24.1% == 25% \n",
    "        - ```P(Sales = High | Gender = Female)``` and ```P(Sales = High | Gender = Male)``` is same/similar to ```P(Sales = High)```\n",
    "            - 10.4% and 11.1% == 10.8% \n",
    "        - ```P(Sales = Elite | Gender = Female)``` and ```P(Sales = Elite | Gender = Male)``` is same/similar to ```P(Sales = Elite)```\n",
    "            - 15.0% and 13.6% == 14.2% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value8 = pd.crosstab(df.Gender, df.totalSalesAcquiredClass)\n",
    "table_norm8 = pd.crosstab(df.Gender, df.totalSalesAcquiredClass, normalize=\"index\")\n",
    "\n",
    "display(table_value8[[\"Basic\", \"Moderate\", \"High\", \"Elite\"]])\n",
    "display(table_norm8[[\"Basic\", \"Moderate\", \"High\", \"Elite\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = [\"Basic\", \"Moderate\", \"High\", \"Elite\"]\n",
    "genders = [\"Female\",\"Male\"]\n",
    "\n",
    "displayProb(genders, sales, table_value8, table_norm8, \"Gender\", \"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **9. City vs Sales** \n",
    "- **Explanation**: \n",
    "    - We want to examine whether the city an employee works at affects their total sales. \n",
    "    - City C20 would be significant as it has the most employees while other cities have a relatively balanced number of employees\n",
    "    - Each city may be geographically dispositioned to have more customers and in turn affect total sales\n",
    "- **Relationship**:\n",
    "    - We can conclude that the **total sales generated is generally dependent of the city an employee works in** as conditional probability is quite different as unconditional probability\n",
    "        - ```P(Sales = Basic | City = C22)``` and ```P(Sales = Basic | Gender = C14)``` is different to ```P(Sales = Basic)```\n",
    "            - 38.2% and 56.8% different to 50% \n",
    "        - ```P(Sales = Moderate | City = C27)``` and ```P(Sales = Moderate | City = C22)``` is same/similar to ```P(Sales = Moderate)```\n",
    "            - 17.1% and 34.2% == 25% \n",
    "        - ```P(Sales = High | City = C15)``` and ```P(Sales = High | City = C12)``` is same/similar to ```P(Sales = High)```\n",
    "            - 3.4% and 18.4% == 10.8% \n",
    "        - ```P(Sales = Elite | City = C11)``` and ```P(Sales = Elite | City = C29)``` is same/similar to ```P(Sales = Elite)```\n",
    "            - 6.2% and 25.6% == 14.2% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value9 = pd.crosstab(df.City, df.totalSalesAcquiredClass)\n",
    "table_norm9 = pd.crosstab(df.City, df.totalSalesAcquiredClass, normalize=\"index\")\n",
    "\n",
    "display_values_9 = table_value9[[\"Basic\", \"Moderate\", \"High\", \"Elite\"]]\n",
    "display_norm_9 = table_norm9[[\"Basic\", \"Moderate\", \"High\", \"Elite\"]]\n",
    "\n",
    "display_values_9 = display_values_9.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "display_norm_9 = display_norm_9.merge(df[['City', 'City_Encoded']].drop_duplicates(), on=\"City\", how=\"left\") # To sort by city code correctly\n",
    "\n",
    "display_values_9 = display_values_9.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "display_norm_9 = display_norm_9.sort_values(by=\"City_Encoded\").drop(columns=\"City_Encoded\")\n",
    "\n",
    "display_values_9.set_index(\"City\")\n",
    "display_norm_9.set_index(\"City\")\n",
    "\n",
    "display(display_values_9)\n",
    "display(display_norm_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P(Sale=Basic) = {UCP_Col(\"Basic\", table_value9, df.shape[0])}\")\n",
    "print(f\"P(Sale=Moderate) = {UCP_Col(\"Moderate\", table_value9, df.shape[0])}\")\n",
    "print(f\"P(Sale=High) = {UCP_Col(\"High\", table_value9, df.shape[0])}\")\n",
    "print(f\"P(Sale=Elite) = {UCP_Col(\"Elite\", table_value9, df.shape[0])}\\n\")\n",
    "\n",
    "sales = [\"Basic\", \"Moderate\", \"High\", \"Elite\"]\n",
    "cities = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', \n",
    "          'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', \n",
    "          'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29'][::3]\n",
    "\n",
    "displayProb(cities, sales, table_value9, table_norm9, \"City\", \"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **10. Time Worked vs Total Sales Acquired** \n",
    "- **Explanation**: We expect that an employee who has worked for a longer time will have more opportunities to generate more sales. As such, we want to investigate the correlation between these two variables\n",
    "- **Relationship**:\n",
    "    - As the correlation coefficient is 0.688, it suggests both are **dependent** and has **a positive correlation between both variables** - the longer an employee has worked, the greater the total sales acquired\n",
    "    - However, as the correlation coefficient is **not as close to 1**, it implies that how long an employee worked is **not the sole factor** in determining the sales acquired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.Time_Worked\n",
    "ys = df.Total_Sales_Acquired\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "plt.title(\"Time_Worked vs TotalSalesAcquired\", fontsize=15)\n",
    "plt.xlabel(\"Time_Worked\", fontsize=12)\n",
    "plt.ylabel(\"TotalSalesAcquired\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_TW_TSA = np.corrcoef(xs, ys)[0][1]\n",
    "cov_TW_TSA = np.cov(xs, ys)[0][1]\n",
    "var_TW = xs.var()\n",
    "var_TSA = ys.var() \n",
    "\n",
    "print(f\"ρ                             = {corr_TW_TSA}\")    #Correlation Coefficient\n",
    "print(f\"Cov(Time Worked, Total Sales) = {cov_TW_TSA}\")     #Cov(X,Y) = Cov(Y,X)\n",
    "print(f\"Var(Time Worked)              = {var_TW}\")\n",
    "print(f\"Var(Total Sales)              = {var_TSA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **11. Designation vs Quarterly Rating** \n",
    "- **Explanation**: \n",
    "    - We want to investigate whether the designation an employee holds have an impact on their ratings\n",
    "    - A higher designation level generate biasness towards an employee's likelihood of receiving a greater rating\n",
    "  \n",
    "- **Relationship**:\n",
    "    - We can conclude that the **rating attained is dependent on the employee's designation** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Rating = 1 | Designation=4) = 52.5%``` is different from ```P(Rating = 1) = 73.5%``` \n",
    "        - ```P(Rating = 2 | Designation=4) = 36.1%``` is different from ```P(Rating = 2) = 15.2%``` \n",
    "    - We can also conclude it is **not necessarily true** that **a higher designation level affects the likelihood of attaing a rating greater than 1**\n",
    "        - ```P(Rating = 3 | Designation=3) > P(Rating = 3 | Designation=2) and P(Rating = 3 | Designation=4)```\n",
    "            - _8.5% > 6.8% and 8.2%_\n",
    "        - ```P(Rating = 4 | Designation=3) > P(Rating = 4 | Designation=2) and P(Rating = 4 | Designation=4)```\n",
    "            - _6.9% > 4.5% and 3.3%_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value11 = pd.crosstab(df.Designation, df.Quarterly_Rating)\n",
    "table_norm11 = pd.crosstab(df.Designation, df.Quarterly_Rating, normalize=\"index\")\n",
    "\n",
    "display(table_value11)\n",
    "display(table_norm11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [1,2,3,4]\n",
    "designations = [1,2,3,4,5]\n",
    "\n",
    "displayProb(designations, ratings, table_value11, table_norm11, \"Designation\", \"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **12. Sales vs Quarterly Rating** \n",
    "- **Explanation**: \n",
    "    - We want to verify that the quarterly rating given to an employee is dependent on their total sales made\n",
    "    - We also want to investigate whether an employee who made more sales are more likely to attain a specific rating than those who made less sales\n",
    "- **Relationship**:\n",
    "    - We can conclude that the **rating attained is dependent on the total sales made** as conditional probability is quite different from unconditional probability\n",
    "        - ```P(Rating = 1 | Total Sales is \"Basic\") = 97.9%``` is different from ```P(Rating = 1) = 73.5%``` \n",
    "        - ```P(Rating = 3 | Total Sales is \"Elite\") = 27.3%``` is different from ```P(Rating = 3) = 7.0%``` \n",
    "    - We can also conclude the second question is **valid** for **quarterly rating of 2, 3 and 4**, but **not for a rating for 1** where employees with \"Basic\" total sales acquired are mostly likely to attain this rating\n",
    "        - ```P(Rating = 4 | Total Sales is \"Elite\") > P(Rating = 4 | Total Sales is \"High\") > P(Rating = 4 | Total Sales is \"Moderate\") > P(Rating = 4 | Total Sales is \"Basic\")```\n",
    "            - _20.72% > 9.48% > 1.30% > 0.00%_\n",
    "        <br><br>\n",
    "        - ```P(Rating = 1 | Total Sales is \"Elite\") > P(Rating = 1 | Total Sales is \"High\") > P(Rating = 1 | Total Sales is \"Moderate\") > P(Rating = 1 | Total Sales is \"Basic\")```\n",
    "            - _21.05% < 48.28% < 65.49% < 97.85%_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_value12 = pd.crosstab(df.totalSalesAcquiredClass, df.Quarterly_Rating)\n",
    "table_norm12 = pd.crosstab(df.totalSalesAcquiredClass, df.Quarterly_Rating, normalize=\"index\")\n",
    "\n",
    "display(table_value12)\n",
    "display(table_norm12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [1,3]    # [1,2,3,4]\n",
    "sales = ['Basic','Moderate','High','Elite']\n",
    "\n",
    "displayProb(sales, ratings, table_value12, table_norm12, \"Sales\", \"Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"phase2\"></a>\n",
    "## Part II: Modeling [12% of final grade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem formulation [15% of Part II]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Formulate one regression problem and one classification based on the dataset, in **no more than 50 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** State which problem (regression or classification) you would be investigating and why, in **no more than 20 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Clearly specify the dependent variable you are predicting, and its significance, in **no more than 20 words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model training [30% of Part II]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Perform feature selection. For each variable, decide if you want to include it as a feature and provide a justification. You may leverage on your analysis in Part I: EDA and/or perform additional analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Split the dataset into train and test sets. Describe how you split step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** State the model(s) you will train, and explain your choice(s), in **no more than 50 words per model**. You only need to\n",
    "train one model, but if you do train more models, limit yourself to no more than three---Grading is based on the validity and soundness of your model, rather than the quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** For each model, perform the training, and report the trained parameters and the training scores, if applicable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model evaluation and selection [30% of Part II]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** For each model, predict the response variable on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Describe the metric you use to evaluate your model(s). Report the test scores for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** If you trained more than one model, identify the final model you would choose for the prediction task, and explain your choice, **in no more than 50 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Findings and conclusion [20% of Part II]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Interpret what your model is implying, and summarize any insight you have drawn from the project. Explain if it is consistent with intuition, and if not, provide a plausible justification. Limit your entire response to **50 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Share any lesson you have learned from the project, in **no more than 50 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Non-technical protocol [5% of Part II]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Describe the detailed contribution of each team member, including both the tangible (e.g., implementation, testing, writing) and intangible (e.g., generating ideas, planning, leadership) efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** List any references and sources you have cited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
